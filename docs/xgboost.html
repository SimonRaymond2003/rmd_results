<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>XGBoost Prediction Model</title>

<script src="site_libs/header-attrs-2.22/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">4th Downs in the NFL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="heckman.html">Heckman Selection</a>
</li>
<li>
  <a href="xgboost.html">XGBoost Prediction</a>
</li>
<li>
  <a href="attendance.html">Attendance Impact</a>
</li>
<li>
  <a href="thirddown.html">Third Down Analysis</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">XGBoost Prediction Model</h1>

</div>


<pre class="r"><code>library(data.table)   

outcome_data &lt;- fread(&quot;predict_outcome.csv.gz&quot;)</code></pre>
<pre class="r"><code># Load library and prepare data
#library(randomForest)
#rf_data &lt;- copy(outcome_data)[, my_id := NULL]
#rf_data[, conversion := as.factor(conversion)]

# Run RF and get OOB AUC
#rf_model &lt;- randomForest(conversion ~ ., data = rf_data, ntree = 100, importance = TRUE)
#pred_oob &lt;- predict(rf_model, type = &quot;prob&quot;)[,2]
#cat(&quot;\nOOB AUC:&quot;, as.numeric(performance(prediction(pred_oob, as.numeric(as.character(rf_data$conversion))), &quot;auc&quot;)@y.values))

# Filter variables based on positive MDA
#mda_scores &lt;- importance(rf_model)[, &quot;MeanDecreaseAccuracy&quot;]
#keep_vars &lt;- unique(c(names(mda_scores[mda_scores &gt; 0]), &quot;my_id&quot;, &quot;conversion&quot;))
#outcome_data &lt;- outcome_data[, .SD, .SDcols = keep_vars]

#cat(&quot;\nVariables kept:&quot;, length(keep_vars), &quot;out of&quot;, ncol(rf_data) + 1)</code></pre>
<pre class="r"><code># Load required libraries
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs &lt;- model.matrix(~ . - 1 - conversion - my_id, data = outcome_data)
y &lt;- as.numeric(as.character(outcome_data$conversion))

# Create parameter grid
grid &lt;- expand.grid(
  eta = seq(0.001, 0.1, by = 0.01),
  max_depth = seq(5, 7, by = 2),
  min_child_weight = seq(1, 1, by = 1),        
  subsample = seq(0.8, 0.8, by = 0.2),
  colsample_bytree = seq(0.8, 0.8, by = 0.2),
  lambda = seq(1, 1, by = 1),                
  alpha = seq(0, 0, by = 1),                  
  gamma = seq(0, 0, by = 0.1),               
  nrounds = seq(100, 500, by = 50)
)

# Sample grid points
conf_lev &lt;- .95
num_max &lt;- 5
n &lt;- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind &lt;- sample(nrow(grid), n, replace = FALSE)
rgrid &lt;- grid[ind, ]

# Set up parallel processing
nc &lt;- detectCores() - 1

# Validation phase
cat(&quot;\nPhase 1: Validation Phase\n&quot;)</code></pre>
<pre><code>## 
## Phase 1: Validation Phase</code></pre>
<pre class="r"><code>n_validations &lt;- 20
validation_results &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
 # cat(&quot;\nTesting parameter set&quot;, j, &quot;of&quot;, nrow(rgrid), &quot;\n&quot;)
  #cat(&quot;eta =&quot;, rgrid[j, &quot;eta&quot;], &quot;, nrounds =&quot;, rgrid[j, &quot;nrounds&quot;], &quot;\n&quot;)
  
  for (i in 1:n_validations) {
    # Create validation split
    idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
    train_x &lt;- xs[idx, ]
    train_y &lt;- y[idx]
    val_x &lt;- xs[-idx, ]
    val_y &lt;- y[-idx]
    
    prm &lt;- list(
      booster = &quot;gbtree&quot;,
      objective = &quot;binary:logistic&quot;,
      max_depth = rgrid[j, &quot;max_depth&quot;],
      eta = rgrid[j, &quot;eta&quot;],
      subsample = rgrid[j, &quot;subsample&quot;],
      colsample_bytree = rgrid[j, &quot;colsample_bytree&quot;],
      gamma = rgrid[j, &quot;gamma&quot;],
      min_child_weight = rgrid[j, &quot;min_child_weight&quot;],
      alpha = rgrid[j, &quot;alpha&quot;],
      lambda = rgrid[j, &quot;lambda&quot;],
      nthread = nc
    )
    
    dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
    mdl &lt;- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, &quot;nrounds&quot;],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p &lt;- predict(mdl, xgb.DMatrix(data = val_x))
    pred &lt;- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
    
    # Calculate Youden&#39;s J Statistic
    roc &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
    tpr &lt;- unlist(roc@y.values)
    fpr &lt;- unlist(roc@x.values)
    j_stats &lt;- tpr - fpr
    validation_j_stats[j, i] &lt;- max(j_stats)
  }
  
  #cat(&quot;Mean AUC:&quot;, mean(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;SD AUC:&quot;, sd(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;Mean J statistic:&quot;, mean(validation_j_stats[j,]), &quot;\n&quot;)
}

# Select best parameters based on validation AUC
best_params_idx &lt;- which.max(rowMeans(validation_results))
best_params &lt;- rgrid[best_params_idx,]
cat(&quot;\nBest parameters:\n&quot;)</code></pre>
<pre><code>## 
## Best parameters:</code></pre>
<pre class="r"><code>print(best_params)</code></pre>
<pre><code>##      eta max_depth min_child_weight subsample colsample_bytree lambda alpha
## 81 0.001         5                1       0.8              0.8      1     0
##    gamma nrounds
## 81     0     300</code></pre>
<pre class="r"><code># Run 100 tests with best parameters
cat(&quot;\nRunning 100 test iterations with best parameters...\n&quot;)</code></pre>
<pre><code>## 
## Running 100 test iterations with best parameters...</code></pre>
<pre class="r"><code>test_aucs &lt;- c()
test_j_stats &lt;- c()
confusion_matrices &lt;- list()
performance_list &lt;- list()
all_thresholds &lt;- c()                             

# Train final model with best parameters
best_params_list &lt;- as.list(best_params[-which(names(best_params) == &quot;nrounds&quot;)])
best_params_list$booster &lt;- &quot;gbtree&quot;
best_params_list$objective &lt;- &quot;binary:logistic&quot;
best_params_list$nthread &lt;- nc

for(i in 1:100) {
  #cat(&quot;\nIteration&quot;, i, &quot;of 100\n&quot;)       
  # Create test split
  idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
  train_x &lt;- xs[idx, ]
  train_y &lt;- y[idx]
  test_x &lt;- xs[-idx, ]
  test_y &lt;- y[-idx]
  
  # Train model
  dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
  mdl &lt;- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[[&quot;nrounds&quot;]],
    verbose = FALSE
  )
  
  # Get predictions
  p &lt;- predict(mdl, xgb.DMatrix(data = test_x))
  pred &lt;- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
  
  # Calculate ROC curve and store
  perf &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
  performance_list[[i]] &lt;- perf
  
  # Find optimal threshold using Youden&#39;s J statistic
  tpr &lt;- unlist(perf@y.values)
  fpr &lt;- unlist(perf@x.values)
  j_stats &lt;- tpr - fpr
  best_j_idx &lt;- which.max(j_stats)
  optimal_threshold &lt;- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] &lt;- optimal_threshold
  test_j_stats[i] &lt;- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class &lt;- ifelse(p &gt;= optimal_threshold, 1, 0)
  cm &lt;- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) &lt;- c(&quot;Pred 1&quot;, &quot;Pred 0&quot;)
  rownames(cm) &lt;- c(&quot;True 1&quot;, &quot;True 0&quot;)
  confusion_matrices[[i]] &lt;- cm
}

# Calculate average confusion matrix
avg_cm &lt;- Reduce(&#39;+&#39;, confusion_matrices) / length(confusion_matrices)

# Print final results
cat(&quot;\nTest Results over 100 iterations:\n&quot;)</code></pre>
<pre><code>## 
## Test Results over 100 iterations:</code></pre>
<pre class="r"><code>cat(&quot;Mean AUC:&quot;, mean(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## Mean AUC: 0.6808301</code></pre>
<pre class="r"><code>cat(&quot;SD AUC:&quot;, sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## SD AUC: 0.01083664</code></pre>
<pre class="r"><code>cat(&quot;Mean Youden&#39;s J:&quot;, mean(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Youden&#39;s J: 0.2904095</code></pre>
<pre class="r"><code>cat(&quot;SD Youden&#39;s J:&quot;, sd(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## SD Youden&#39;s J: 0.01916523</code></pre>
<pre class="r"><code>cat(&quot;Mean Optimal Threshold:&quot;, mean(all_thresholds), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Optimal Threshold: 0.5032765</code></pre>
<pre class="r"><code>cat(&quot;95% CI for AUC:&quot;, mean(test_aucs) - 1.96 * sd(test_aucs), 
    &quot;to&quot;, mean(test_aucs) + 1.96 * sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## 95% CI for AUC: 0.6595903 to 0.70207</code></pre>
<pre class="r"><code>cat(&quot;\nAverage Confusion Matrix:\n&quot;)</code></pre>
<pre><code>## 
## Average Confusion Matrix:</code></pre>
<pre class="r"><code>print(avg_cm)</code></pre>
<pre><code>##         
##          Pred 1 Pred 0
##   True 1 519.90 253.07
##   True 0 270.78 437.93</code></pre>
<pre class="r"><code># Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type=&quot;l&quot;, lty=2, 
     xlab=&quot;False Positive Rate&quot;, ylab=&quot;True Positive Rate&quot;,
     main=&quot;ROC Curve&quot;)

# Calculate average ROC curve with confidence intervals
fpr_grid &lt;- seq(0, 1, length.out = 100)
tpr_matrix &lt;- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i &lt;- performance_list[[i]]
  tpr_matrix[i,] &lt;- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr &lt;- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col=&quot;red&quot;, lwd=2)

# Add optimal threshold point
opt_point_idx &lt;- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col=&quot;blue&quot;, pch=19, cex=1.5)

# Add confidence interval
ci_lower &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col=&quot;gray&quot;, lty=2)
lines(fpr_grid, ci_upper, col=&quot;gray&quot;, lty=2)

# Add legend
legend(&quot;bottomright&quot;, 
       legend=c(&quot;Random&quot;, &quot;Average ROC&quot;, &quot;95% CI&quot;, &quot;Optimal Threshold&quot;),
       col=c(&quot;black&quot;, &quot;red&quot;, &quot;gray&quot;, &quot;blue&quot;), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-3-1.png" width="672" /></p>
<pre class="r"><code># Load required libraries
library(data.table)
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs &lt;- model.matrix(~ . - 1 - conversion - my_id, data = outcome_data)
y &lt;- as.numeric(as.character(outcome_data$conversion))

# Create parameter grid - only tune eta and nrounds
grid &lt;- expand.grid(
  eta = seq(0.001, 0.1, by = 0.003),
  nrounds = seq(50, 500, by = 50)
)

# Sample grid points
conf_lev &lt;- .95
num_max &lt;- 5
n &lt;- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind &lt;- sample(nrow(grid), n, replace = FALSE)
rgrid &lt;- grid[ind, ]

# Set up parallel processing
nc &lt;- detectCores() - 1

# Validation phase
cat(&quot;\nPhase 1: Validation Phase\n&quot;)</code></pre>
<pre><code>## 
## Phase 1: Validation Phase</code></pre>
<pre class="r"><code>n_validations &lt;- 20
validation_results &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
  #cat(&quot;\nTesting parameter set&quot;, j, &quot;of&quot;, nrow(rgrid), &quot;\n&quot;)
  #cat(&quot;eta =&quot;, rgrid[j, &quot;eta&quot;], &quot;, nrounds =&quot;, rgrid[j, &quot;nrounds&quot;], &quot;\n&quot;)
  
  for (i in 1:n_validations) {
    # Create validation split
    idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
    train_x &lt;- xs[idx, ]
    train_y &lt;- y[idx]
    val_x &lt;- xs[-idx, ]
    val_y &lt;- y[-idx]
    
    prm &lt;- list(
      booster = &quot;gblinear&quot;,
      objective = &quot;binary:logistic&quot;,
      eta = rgrid[j, &quot;eta&quot;],
      nthread = nc
    )
    
    dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
    mdl &lt;- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, &quot;nrounds&quot;],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p &lt;- predict(mdl, xgb.DMatrix(data = val_x))
    pred &lt;- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
    
    # Calculate Youden&#39;s J Statistic
    roc &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
    tpr &lt;- unlist(roc@y.values)
    fpr &lt;- unlist(roc@x.values)
    j_stats &lt;- tpr - fpr
    validation_j_stats[j, i] &lt;- max(j_stats)
  }
  
  #cat(&quot;Mean AUC:&quot;, mean(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;SD AUC:&quot;, sd(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;Mean J statistic:&quot;, mean(validation_j_stats[j,]), &quot;\n&quot;)
}

# Select best parameters based on validation AUC
best_params_idx &lt;- which.max(rowMeans(validation_results))
best_params &lt;- rgrid[best_params_idx,]
cat(&quot;\nBest parameters:\n&quot;)</code></pre>
<pre><code>## 
## Best parameters:</code></pre>
<pre class="r"><code>print(best_params)</code></pre>
<pre><code>##       eta nrounds
## 239 0.001     400</code></pre>
<pre class="r"><code># Run X tests with best parameters
cat(&quot;\nRunning X test iterations with best parameters...\n&quot;)</code></pre>
<pre><code>## 
## Running X test iterations with best parameters...</code></pre>
<pre class="r"><code>test_aucs &lt;- c()
test_j_stats &lt;- c()
confusion_matrices &lt;- list()
performance_list &lt;- list()
all_thresholds &lt;- c()

# Train final model with best parameters
best_params_list &lt;- as.list(best_params[-which(names(best_params) == &quot;nrounds&quot;)])
best_params_list$booster &lt;- &quot;gblinear&quot;
best_params_list$objective &lt;- &quot;binary:logistic&quot;
best_params_list$nthread &lt;- nc

for(i in 1:100) {
  #cat(&quot;\nIteration&quot;, i, &quot;of 100\n&quot;)       
  # Create test split
  idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
  train_x &lt;- xs[idx, ]
  train_y &lt;- y[idx]
  test_x &lt;- xs[-idx, ]
  test_y &lt;- y[-idx]
  
  # Train model
  dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
  mdl &lt;- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[[&quot;nrounds&quot;]],
    verbose = FALSE
  )
  
  # Get predictions
  p &lt;- predict(mdl, xgb.DMatrix(data = test_x))
  pred &lt;- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
  
  # Calculate ROC curve and store
  perf &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
  performance_list[[i]] &lt;- perf
  
  # Find optimal threshold using Youden&#39;s J statistic
  tpr &lt;- unlist(perf@y.values)
  fpr &lt;- unlist(perf@x.values)
  j_stats &lt;- tpr - fpr
  best_j_idx &lt;- which.max(j_stats)
  optimal_threshold &lt;- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] &lt;- optimal_threshold
  test_j_stats[i] &lt;- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class &lt;- ifelse(p &gt;= optimal_threshold, 1, 0)
  cm &lt;- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) &lt;- c(&quot;Pred 1&quot;, &quot;Pred 0&quot;)
  rownames(cm) &lt;- c(&quot;True 1&quot;, &quot;True 0&quot;)
  confusion_matrices[[i]] &lt;- cm
}

# Calculate average confusion matrix
avg_cm &lt;- Reduce(&#39;+&#39;, confusion_matrices) / length(confusion_matrices)

# Print final results
cat(&quot;\nTest Results over 100 iterations:\n&quot;)</code></pre>
<pre><code>## 
## Test Results over 100 iterations:</code></pre>
<pre class="r"><code>cat(&quot;Mean AUC:&quot;, mean(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## Mean AUC: 0.6499744</code></pre>
<pre class="r"><code>cat(&quot;SD AUC:&quot;, sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## SD AUC: 0.01107767</code></pre>
<pre class="r"><code>cat(&quot;Mean Youden&#39;s J:&quot;, mean(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Youden&#39;s J: 0.236753</code></pre>
<pre class="r"><code>cat(&quot;SD Youden&#39;s J:&quot;, sd(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## SD Youden&#39;s J: 0.01993908</code></pre>
<pre class="r"><code>cat(&quot;Mean Optimal Threshold:&quot;, mean(all_thresholds), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Optimal Threshold: 0.5076797</code></pre>
<pre class="r"><code>cat(&quot;95% CI for AUC:&quot;, mean(test_aucs) - 1.96 * sd(test_aucs), 
    &quot;to&quot;, mean(test_aucs) + 1.96 * sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## 95% CI for AUC: 0.6282621 to 0.6716866</code></pre>
<pre class="r"><code>cat(&quot;\nAverage Confusion Matrix:\n&quot;)</code></pre>
<pre><code>## 
## Average Confusion Matrix:</code></pre>
<pre class="r"><code>print(avg_cm)</code></pre>
<pre><code>##         
##          Pred 1 Pred 0
##   True 1 507.34 265.99
##   True 0 296.82 410.81</code></pre>
<pre class="r"><code># Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type=&quot;l&quot;, lty=2, 
     xlab=&quot;False Positive Rate&quot;, ylab=&quot;True Positive Rate&quot;,
     main=&quot;ROC Curve&quot;)

# Calculate average ROC curve with confidence intervals
fpr_grid &lt;- seq(0, 1, length.out = 100)
tpr_matrix &lt;- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i &lt;- performance_list[[i]]
  tpr_matrix[i,] &lt;- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr &lt;- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col=&quot;red&quot;, lwd=2)

# Add optimal threshold point
opt_point_idx &lt;- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col=&quot;blue&quot;, pch=19, cex=1.5)

# Add confidence interval
ci_lower &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col=&quot;gray&quot;, lty=2)
lines(fpr_grid, ci_upper, col=&quot;gray&quot;, lty=2)

# Add legend
legend(&quot;bottomright&quot;, 
       legend=c(&quot;Random&quot;, &quot;Average ROC&quot;, &quot;95% CI&quot;, &quot;Optimal Threshold&quot;),
       col=c(&quot;black&quot;, &quot;red&quot;, &quot;gray&quot;, &quot;blue&quot;), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>

<div id="rmd-source-code">---
title: "XGBoost Prediction Model"
output: html_document
---


```{r options, include=FALSE}
options(max.print=10000)
```

```{r}
library(data.table)   

outcome_data <- fread("predict_outcome.csv.gz")

```

```{r}
# Load library and prepare data
#library(randomForest)
#rf_data <- copy(outcome_data)[, my_id := NULL]
#rf_data[, conversion := as.factor(conversion)]

# Run RF and get OOB AUC
#rf_model <- randomForest(conversion ~ ., data = rf_data, ntree = 100, importance = TRUE)
#pred_oob <- predict(rf_model, type = "prob")[,2]
#cat("\nOOB AUC:", as.numeric(performance(prediction(pred_oob, as.numeric(as.character(rf_data$conversion))), "auc")@y.values))

# Filter variables based on positive MDA
#mda_scores <- importance(rf_model)[, "MeanDecreaseAccuracy"]
#keep_vars <- unique(c(names(mda_scores[mda_scores > 0]), "my_id", "conversion"))
#outcome_data <- outcome_data[, .SD, .SDcols = keep_vars]

#cat("\nVariables kept:", length(keep_vars), "out of", ncol(rf_data) + 1)
```



```{r, warning=FALSE, message=FALSE}                        
# Load required libraries
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs <- model.matrix(~ . - 1 - conversion - my_id, data = outcome_data)
y <- as.numeric(as.character(outcome_data$conversion))

# Create parameter grid
grid <- expand.grid(
  eta = seq(0.001, 0.1, by = 0.01),
  max_depth = seq(5, 7, by = 2),
  min_child_weight = seq(1, 1, by = 1),        
  subsample = seq(0.8, 0.8, by = 0.2),
  colsample_bytree = seq(0.8, 0.8, by = 0.2),
  lambda = seq(1, 1, by = 1),                
  alpha = seq(0, 0, by = 1),                  
  gamma = seq(0, 0, by = 0.1),               
  nrounds = seq(100, 500, by = 50)
)

# Sample grid points
conf_lev <- .95
num_max <- 5
n <- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind <- sample(nrow(grid), n, replace = FALSE)
rgrid <- grid[ind, ]

# Set up parallel processing
nc <- detectCores() - 1

# Validation phase
cat("\nPhase 1: Validation Phase\n")
n_validations <- 20
validation_results <- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats <- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
 # cat("\nTesting parameter set", j, "of", nrow(rgrid), "\n")
  #cat("eta =", rgrid[j, "eta"], ", nrounds =", rgrid[j, "nrounds"], "\n")
  
  for (i in 1:n_validations) {
    # Create validation split
    idx <- unique(sample(nrow(xs), nrow(xs), T))
    train_x <- xs[idx, ]
    train_y <- y[idx]
    val_x <- xs[-idx, ]
    val_y <- y[-idx]
    
    prm <- list(
      booster = "gbtree",
      objective = "binary:logistic",
      max_depth = rgrid[j, "max_depth"],
      eta = rgrid[j, "eta"],
      subsample = rgrid[j, "subsample"],
      colsample_bytree = rgrid[j, "colsample_bytree"],
      gamma = rgrid[j, "gamma"],
      min_child_weight = rgrid[j, "min_child_weight"],
      alpha = rgrid[j, "alpha"],
      lambda = rgrid[j, "lambda"],
      nthread = nc
    )
    
    dm_train <- xgb.DMatrix(data = train_x, label = train_y)
    mdl <- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, "nrounds"],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p <- predict(mdl, xgb.DMatrix(data = val_x))
    pred <- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] <- performance(pred, "auc")@y.values[[1]]
    
    # Calculate Youden's J Statistic
    roc <- performance(pred, "tpr", "fpr")
    tpr <- unlist(roc@y.values)
    fpr <- unlist(roc@x.values)
    j_stats <- tpr - fpr
    validation_j_stats[j, i] <- max(j_stats)
  }
  
  #cat("Mean AUC:", mean(validation_results[j,]), "\n")
  #cat("SD AUC:", sd(validation_results[j,]), "\n")
  #cat("Mean J statistic:", mean(validation_j_stats[j,]), "\n")
}

# Select best parameters based on validation AUC
best_params_idx <- which.max(rowMeans(validation_results))
best_params <- rgrid[best_params_idx,]
cat("\nBest parameters:\n")
print(best_params)

# Run 100 tests with best parameters
cat("\nRunning 100 test iterations with best parameters...\n")
test_aucs <- c()
test_j_stats <- c()
confusion_matrices <- list()
performance_list <- list()
all_thresholds <- c()                             

# Train final model with best parameters
best_params_list <- as.list(best_params[-which(names(best_params) == "nrounds")])
best_params_list$booster <- "gbtree"
best_params_list$objective <- "binary:logistic"
best_params_list$nthread <- nc

for(i in 1:100) {
  #cat("\nIteration", i, "of 100\n")       
  # Create test split
  idx <- unique(sample(nrow(xs), nrow(xs), T))
  train_x <- xs[idx, ]
  train_y <- y[idx]
  test_x <- xs[-idx, ]
  test_y <- y[-idx]
  
  # Train model
  dm_train <- xgb.DMatrix(data = train_x, label = train_y)
  mdl <- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[["nrounds"]],
    verbose = FALSE
  )
  
  # Get predictions
  p <- predict(mdl, xgb.DMatrix(data = test_x))
  pred <- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] <- performance(pred, "auc")@y.values[[1]]
  
  # Calculate ROC curve and store
  perf <- performance(pred, "tpr", "fpr")
  performance_list[[i]] <- perf
  
  # Find optimal threshold using Youden's J statistic
  tpr <- unlist(perf@y.values)
  fpr <- unlist(perf@x.values)
  j_stats <- tpr - fpr
  best_j_idx <- which.max(j_stats)
  optimal_threshold <- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] <- optimal_threshold
  test_j_stats[i] <- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class <- ifelse(p >= optimal_threshold, 1, 0)
  cm <- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) <- c("Pred 1", "Pred 0")
  rownames(cm) <- c("True 1", "True 0")
  confusion_matrices[[i]] <- cm
}

# Calculate average confusion matrix
avg_cm <- Reduce('+', confusion_matrices) / length(confusion_matrices)

# Print final results
cat("\nTest Results over 100 iterations:\n")
cat("Mean AUC:", mean(test_aucs), "\n")
cat("SD AUC:", sd(test_aucs), "\n")
cat("Mean Youden's J:", mean(test_j_stats), "\n")
cat("SD Youden's J:", sd(test_j_stats), "\n")
cat("Mean Optimal Threshold:", mean(all_thresholds), "\n")
cat("95% CI for AUC:", mean(test_aucs) - 1.96 * sd(test_aucs), 
    "to", mean(test_aucs) + 1.96 * sd(test_aucs), "\n")
cat("\nAverage Confusion Matrix:\n")
print(avg_cm)

# Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type="l", lty=2, 
     xlab="False Positive Rate", ylab="True Positive Rate",
     main="ROC Curve")

# Calculate average ROC curve with confidence intervals
fpr_grid <- seq(0, 1, length.out = 100)
tpr_matrix <- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i <- performance_list[[i]]
  tpr_matrix[i,] <- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr <- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col="red", lwd=2)

# Add optimal threshold point
opt_point_idx <- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col="blue", pch=19, cex=1.5)

# Add confidence interval
ci_lower <- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper <- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col="gray", lty=2)
lines(fpr_grid, ci_upper, col="gray", lty=2)

# Add legend
legend("bottomright", 
       legend=c("Random", "Average ROC", "95% CI", "Optimal Threshold"),
       col=c("black", "red", "gray", "blue"), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))
```


```{r, warning=FALSE, message=FALSE}
# Load required libraries
library(data.table)
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs <- model.matrix(~ . - 1 - conversion - my_id, data = outcome_data)
y <- as.numeric(as.character(outcome_data$conversion))

# Create parameter grid - only tune eta and nrounds
grid <- expand.grid(
  eta = seq(0.001, 0.1, by = 0.003),
  nrounds = seq(50, 500, by = 50)
)

# Sample grid points
conf_lev <- .95
num_max <- 5
n <- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind <- sample(nrow(grid), n, replace = FALSE)
rgrid <- grid[ind, ]

# Set up parallel processing
nc <- detectCores() - 1

# Validation phase
cat("\nPhase 1: Validation Phase\n")
n_validations <- 20
validation_results <- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats <- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
  #cat("\nTesting parameter set", j, "of", nrow(rgrid), "\n")
  #cat("eta =", rgrid[j, "eta"], ", nrounds =", rgrid[j, "nrounds"], "\n")
  
  for (i in 1:n_validations) {
    # Create validation split
    idx <- unique(sample(nrow(xs), nrow(xs), T))
    train_x <- xs[idx, ]
    train_y <- y[idx]
    val_x <- xs[-idx, ]
    val_y <- y[-idx]
    
    prm <- list(
      booster = "gblinear",
      objective = "binary:logistic",
      eta = rgrid[j, "eta"],
      nthread = nc
    )
    
    dm_train <- xgb.DMatrix(data = train_x, label = train_y)
    mdl <- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, "nrounds"],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p <- predict(mdl, xgb.DMatrix(data = val_x))
    pred <- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] <- performance(pred, "auc")@y.values[[1]]
    
    # Calculate Youden's J Statistic
    roc <- performance(pred, "tpr", "fpr")
    tpr <- unlist(roc@y.values)
    fpr <- unlist(roc@x.values)
    j_stats <- tpr - fpr
    validation_j_stats[j, i] <- max(j_stats)
  }
  
  #cat("Mean AUC:", mean(validation_results[j,]), "\n")
  #cat("SD AUC:", sd(validation_results[j,]), "\n")
  #cat("Mean J statistic:", mean(validation_j_stats[j,]), "\n")
}

# Select best parameters based on validation AUC
best_params_idx <- which.max(rowMeans(validation_results))
best_params <- rgrid[best_params_idx,]
cat("\nBest parameters:\n")
print(best_params)

# Run X tests with best parameters
cat("\nRunning X test iterations with best parameters...\n")
test_aucs <- c()
test_j_stats <- c()
confusion_matrices <- list()
performance_list <- list()
all_thresholds <- c()

# Train final model with best parameters
best_params_list <- as.list(best_params[-which(names(best_params) == "nrounds")])
best_params_list$booster <- "gblinear"
best_params_list$objective <- "binary:logistic"
best_params_list$nthread <- nc

for(i in 1:100) {
  #cat("\nIteration", i, "of 100\n")       
  # Create test split
  idx <- unique(sample(nrow(xs), nrow(xs), T))
  train_x <- xs[idx, ]
  train_y <- y[idx]
  test_x <- xs[-idx, ]
  test_y <- y[-idx]
  
  # Train model
  dm_train <- xgb.DMatrix(data = train_x, label = train_y)
  mdl <- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[["nrounds"]],
    verbose = FALSE
  )
  
  # Get predictions
  p <- predict(mdl, xgb.DMatrix(data = test_x))
  pred <- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] <- performance(pred, "auc")@y.values[[1]]
  
  # Calculate ROC curve and store
  perf <- performance(pred, "tpr", "fpr")
  performance_list[[i]] <- perf
  
  # Find optimal threshold using Youden's J statistic
  tpr <- unlist(perf@y.values)
  fpr <- unlist(perf@x.values)
  j_stats <- tpr - fpr
  best_j_idx <- which.max(j_stats)
  optimal_threshold <- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] <- optimal_threshold
  test_j_stats[i] <- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class <- ifelse(p >= optimal_threshold, 1, 0)
  cm <- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) <- c("Pred 1", "Pred 0")
  rownames(cm) <- c("True 1", "True 0")
  confusion_matrices[[i]] <- cm
}

# Calculate average confusion matrix
avg_cm <- Reduce('+', confusion_matrices) / length(confusion_matrices)

# Print final results
cat("\nTest Results over 100 iterations:\n")
cat("Mean AUC:", mean(test_aucs), "\n")
cat("SD AUC:", sd(test_aucs), "\n")
cat("Mean Youden's J:", mean(test_j_stats), "\n")
cat("SD Youden's J:", sd(test_j_stats), "\n")
cat("Mean Optimal Threshold:", mean(all_thresholds), "\n")
cat("95% CI for AUC:", mean(test_aucs) - 1.96 * sd(test_aucs), 
    "to", mean(test_aucs) + 1.96 * sd(test_aucs), "\n")
cat("\nAverage Confusion Matrix:\n")
print(avg_cm)

# Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type="l", lty=2, 
     xlab="False Positive Rate", ylab="True Positive Rate",
     main="ROC Curve")

# Calculate average ROC curve with confidence intervals
fpr_grid <- seq(0, 1, length.out = 100)
tpr_matrix <- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i <- performance_list[[i]]
  tpr_matrix[i,] <- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr <- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col="red", lwd=2)

# Add optimal threshold point
opt_point_idx <- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col="blue", pch=19, cex=1.5)

# Add confidence interval
ci_lower <- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper <- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col="gray", lty=2)
lines(fpr_grid, ci_upper, col="gray", lty=2)

# Add legend
legend("bottomright", 
       legend=c("Random", "Average ROC", "95% CI", "Optimal Threshold"),
       col=c("black", "red", "gray", "blue"), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))
```

</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("xgboost.Rmd");
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
