<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>XGBoost Prediction Model</title>

<script src="site_libs/header-attrs-2.22/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
#rmd-source-code {
  display: none;
}
</style>


<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">4th Downs in the NFL</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="heckman.html">Heckman Selection</a>
</li>
<li>
  <a href="xgboost.html">XGBoost Prediction</a>
</li>
<li>
  <a href="attendance_binary.html">Attendance Impact Binary</a>
</li>
<li>
  <a href="attendance_pcts.html">Attendance Impact Percentages</a>
</li>
<li>
  <a href="attendance_totals.html">Attendance Impact Totals</a>
</li>
<li>
  <a href="thirddown.html">Third Down Analysis</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
<li role="separator" class="divider"></li>
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">XGBoost Prediction Model</h1>

</div>


<pre class="r"><code>library(data.table)   

outcome_data &lt;- fread(&quot;predict_outcome.csv.gz&quot;)

# Filter out year*_team columns
year_cols &lt;- grep(&quot;^year[0-9]+_team&quot;, names(outcome_data), value = TRUE)
outcome_data[, (year_cols) := NULL]</code></pre>
<pre class="r"><code># Function to check column variance and other potential issues
check_columns &lt;- function(dt) {
  # Create a list to store results
  col_issues &lt;- list(
    zero_var = character(),
    all_na = character(),
    perfect_cor = character(),
    character_cols = character()
  )
  
  # First, identify character columns (except my_id)
  for(col in names(dt)) {
    if(is.character(dt[[col]]) &amp;&amp; col != &quot;my_id&quot;) {
      col_issues$character_cols &lt;- c(col_issues$character_cols, col)
    }
  }
  
  # Get numeric columns only
  numeric_cols &lt;- names(dt)[sapply(dt, is.numeric)]
  numeric_cols &lt;- setdiff(numeric_cols, &quot;conversion&quot;)  # exclude target variable
  
  # Check each numeric column
  for(col in numeric_cols) {
    # Get column data without NAs
    col_data &lt;- dt[[col]][!is.na(dt[[col]])]
    
    # Check for zero variance
    if(length(unique(col_data)) == 1) {
      col_issues$zero_var &lt;- c(col_issues$zero_var, col)
      next
    }
    
    # Check for all NA
    if(all(is.na(dt[[col]]))) {
      col_issues$all_na &lt;- c(col_issues$all_na, col)
    }
  }
  
  # Check correlations for remaining numeric columns
  remaining_cols &lt;- setdiff(numeric_cols, 
                          unique(c(col_issues$zero_var, col_issues$all_na)))
  
  if(length(remaining_cols) &gt; 1) {
    # Create correlation matrix
    cor_matrix &lt;- cor(dt[, ..remaining_cols], use = &quot;pairwise.complete.obs&quot;)
    
    # Find highly correlated pairs
    for(i in 1:(length(remaining_cols)-1)) {
      for(j in (i+1):length(remaining_cols)) {
        if(!is.na(cor_matrix[i,j]) &amp;&amp; abs(cor_matrix[i,j]) &gt; 0.9999) {
          col_issues$perfect_cor &lt;- c(col_issues$perfect_cor, remaining_cols[j])
        }
      }
    }
  }
  
  return(col_issues)
}

# Find problematic columns
issues &lt;- check_columns(outcome_data)

# Print summary of issues found
cat(&quot;Found the following issues:\n&quot;)</code></pre>
<pre><code>## Found the following issues:</code></pre>
<pre class="r"><code>if(length(issues$character_cols) &gt; 0) {
  cat(&quot;\nCharacter columns (excluding my_id):&quot;, paste(issues$character_cols, collapse=&quot;, &quot;))
}
if(length(issues$zero_var) &gt; 0) {
  cat(&quot;\nZero variance columns:&quot;, paste(issues$zero_var, collapse=&quot;, &quot;))
}
if(length(issues$all_na) &gt; 0) {
  cat(&quot;\nAll NA columns:&quot;, paste(issues$all_na, collapse=&quot;, &quot;))
}
if(length(issues$perfect_cor) &gt; 0) {
  cat(&quot;\nPerfectly correlated columns:&quot;, paste(unique(issues$perfect_cor), collapse=&quot;, &quot;))
}

# Combine all problematic columns
problem_cols &lt;- unique(c(issues$zero_var, issues$all_na, 
                        issues$perfect_cor, issues$character_cols))

# Remove problematic columns
if(length(problem_cols) &gt; 0) {
  outcome_data[, (problem_cols) := NULL]
}

# Print summary of remaining columns
cat(&quot;\n\nRemoved&quot;, length(problem_cols), &quot;problematic columns&quot;)</code></pre>
<pre><code>## 
## 
## Removed 0 problematic columns</code></pre>
<pre class="r"><code>cat(&quot;\nRemaining columns:&quot;, ncol(outcome_data))</code></pre>
<pre><code>## 
## Remaining columns: 148</code></pre>
<pre class="r"><code># Load library and prepare data
#library(randomForest)
#rf_data &lt;- copy(outcome_data)[, my_id := NULL]
#rf_data[, conversion := as.factor(conversion)]

# Run RF and get OOB AUC
#rf_model &lt;- randomForest(conversion ~ ., data = rf_data, ntree = 100, importance = TRUE)
#pred_oob &lt;- predict(rf_model, type = &quot;prob&quot;)[,2]
#cat(&quot;\nOOB AUC:&quot;, as.numeric(performance(prediction(pred_oob, as.numeric(as.character(rf_data$conversion))), &quot;auc&quot;)@y.values))

# Filter variables based on positive MDA
#mda_scores &lt;- importance(rf_model)[, &quot;MeanDecreaseAccuracy&quot;]
#keep_vars &lt;- unique(c(names(mda_scores[mda_scores &gt; 0]), &quot;my_id&quot;, &quot;conversion&quot;))
#outcome_data &lt;- outcome_data[, .SD, .SDcols = keep_vars]

#cat(&quot;\nVariables kept:&quot;, length(keep_vars), &quot;out of&quot;, ncol(rf_data) + 1)</code></pre>
<pre class="r"><code>library(randomForest)</code></pre>
<pre><code>## randomForest 4.7-1.1</code></pre>
<pre><code>## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre class="r"><code>library(ROCR)  # Added this library

# Initialize variables for RF loop
rf_data &lt;- copy(outcome_data)[, my_id := NULL]
rf_data[, conversion := as.factor(conversion)]
best_auc &lt;- 0
previous_data &lt;- NULL

# Iterative RF process for variable selection
while(TRUE) {
    # Run RF
    rf_model &lt;- randomForest(conversion ~ ., data = rf_data, ntree = 100, importance = TRUE)
    pred_oob &lt;- predict(rf_model, type = &quot;prob&quot;)[,2]
    
    # Calculate OOB AUC using ROCR
    pred &lt;- prediction(pred_oob, as.numeric(as.character(rf_data$conversion)))
    current_auc &lt;- as.numeric(performance(pred, &quot;auc&quot;)@y.values)
    
    cat(&quot;\nCurrent AUC:&quot;, round(current_auc, 4), &quot;with&quot;, ncol(rf_data)-1, &quot;variables&quot;)
    
    # Check if AUC dropped
    if(!is.null(previous_data) &amp;&amp; current_auc &lt; best_auc) {
        cat(&quot;\nAUC dropped, reverting to previous state&quot;)
        outcome_data &lt;- previous_data
        break
    }
    
    # Update best and prepare for next iteration
    if(current_auc &gt; best_auc) {
        best_auc &lt;- current_auc
        previous_data &lt;- copy(outcome_data)
    }
    
    # Filter variables based on positive MDA
    mda_scores &lt;- importance(rf_model)[, &quot;MeanDecreaseAccuracy&quot;]
    keep_vars &lt;- unique(c(names(mda_scores[mda_scores &gt; 0]), &quot;my_id&quot;, &quot;conversion&quot;))
    
    # Update data for next iteration
    outcome_data &lt;- outcome_data[, .SD, .SDcols = keep_vars]
    rf_data &lt;- copy(outcome_data)[, my_id := NULL]
    rf_data[, conversion := as.factor(conversion)]
}</code></pre>
<pre><code>## 
## Current AUC: 0.639 with 146 variables
## Current AUC: 0.6431 with 98 variables
## Current AUC: 0.6475 with 76 variables
## Current AUC: 0.642 with 64 variables
## AUC dropped, reverting to previous state</code></pre>
<pre class="r"><code>#kill my id
outcome_data$my_id &lt;- NULL</code></pre>
<pre class="r"><code># Run 100 tests with linear model
cat(&quot;\nRunning 100 test iterations with linear model...\n&quot;)</code></pre>
<pre><code>## 
## Running 100 test iterations with linear model...</code></pre>
<pre class="r"><code>test_aucs &lt;- c()
test_j_stats &lt;- c()
confusion_matrices &lt;- list()
performance_list &lt;- list()
all_thresholds &lt;- c()

# Convert data for linear model
model_data &lt;- copy(outcome_data)
model_data[, conversion := as.numeric(as.character(conversion))]

# Run 100 tests with linear model
test_aucs &lt;- c()
test_j_stats &lt;- c()
confusion_matrices &lt;- list()
performance_list &lt;- list()
all_thresholds &lt;- c()

# Convert data for linear model
model_data &lt;- copy(outcome_data)
model_data[, conversion := as.numeric(as.character(conversion))]

for(i in 1:100) {
  # Create test split
  idx &lt;- sample(1:nrow(model_data), size = floor(0.7 * nrow(model_data)))  # Changed sampling approach
  train_data &lt;- model_data[idx, ]
  test_data &lt;- model_data[-idx, ]
  
  # Train model
  mdl &lt;- lm(conversion ~ ., data = train_data)
  
  # Get predictions and handle potential issues
  p &lt;- predict(mdl, test_data)
  
  # Clean predictions
  p[is.na(p)] &lt;- 0  # Handle NAs
  p[is.infinite(p)] &lt;- 1  # Handle Inf
  p[p &gt; 1] &lt;- 1  # Bound predictions
  p[p &lt; 0] &lt;- 0
  
  # Convert predictions and actual values to numeric vectors
  pred_values &lt;- as.numeric(p)
  actual_values &lt;- as.numeric(test_data$conversion)
  
  # Check for any remaining issues
  if(any(is.na(pred_values)) || any(is.infinite(pred_values))) {
    cat(&quot;Warning: Invalid predictions in iteration&quot;, i, &quot;\n&quot;)
    next
  }
  
  # Create ROCR prediction object with error handling
  tryCatch({
    pred &lt;- prediction(pred_values, actual_values)
    
    # Calculate AUC
    perf_auc &lt;- performance(pred, &quot;auc&quot;)
    test_aucs[i] &lt;- perf_auc@y.values[[1]]
    
    # Calculate ROC curve
    perf &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
    performance_list[[i]] &lt;- perf
    
    # Find optimal threshold using Youden&#39;s J statistic
    tpr &lt;- unlist(perf@y.values)
    fpr &lt;- unlist(perf@x.values)
    j_stats &lt;- tpr - fpr
    best_j_idx &lt;- which.max(j_stats)
    optimal_threshold &lt;- unlist(perf@alpha.values)[best_j_idx]
    all_thresholds[i] &lt;- optimal_threshold
    test_j_stats[i] &lt;- j_stats[best_j_idx]
    
    # Create confusion matrix
    pred_class &lt;- ifelse(pred_values &gt;= optimal_threshold, 1, 0)
    cm &lt;- table(factor(actual_values, levels=c(1,0)), 
               factor(pred_class, levels=c(1,0)))
    colnames(cm) &lt;- c(&quot;Pred 1&quot;, &quot;Pred 0&quot;)
    rownames(cm) &lt;- c(&quot;True 1&quot;, &quot;True 0&quot;)
    confusion_matrices[[i]] &lt;- cm
  }, error = function(e) {
    cat(&quot;Error in iteration&quot;, i, &quot;:&quot;, e$message, &quot;\n&quot;)
  })
}

# Calculate average confusion matrix
avg_cm &lt;- Reduce(&#39;+&#39;, confusion_matrices) / length(confusion_matrices)

# Print final results
cat(&quot;\nTest Results over 100 iterations:\n&quot;)</code></pre>
<pre><code>## 
## Test Results over 100 iterations:</code></pre>
<pre class="r"><code>cat(&quot;Mean AUC:&quot;, mean(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## Mean AUC: 0.6798238</code></pre>
<pre class="r"><code>cat(&quot;SD AUC:&quot;, sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## SD AUC: 0.01038273</code></pre>
<pre class="r"><code>cat(&quot;Mean Youden&#39;s J:&quot;, mean(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Youden&#39;s J: 0.2779667</code></pre>
<pre class="r"><code>cat(&quot;SD Youden&#39;s J:&quot;, sd(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## SD Youden&#39;s J: 0.01880664</code></pre>
<pre class="r"><code>cat(&quot;Mean Optimal Threshold:&quot;, mean(all_thresholds), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Optimal Threshold: 0.5120119</code></pre>
<pre class="r"><code>cat(&quot;95% CI for AUC:&quot;, mean(test_aucs) - 1.96 * sd(test_aucs), 
    &quot;to&quot;, mean(test_aucs) + 1.96 * sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## 95% CI for AUC: 0.6594737 to 0.700174</code></pre>
<pre class="r"><code>cat(&quot;\nAverage Confusion Matrix:\n&quot;)</code></pre>
<pre><code>## 
## Average Confusion Matrix:</code></pre>
<pre class="r"><code>print(avg_cm)</code></pre>
<pre><code>##         
##          Pred 1 Pred 0
##   True 1 419.04 210.26
##   True 0 223.85 352.85</code></pre>
<pre class="r"><code># Plotting AUC distribution - removed type=&quot;o&quot; to not connect dots
plot(test_aucs, col=&quot;red&quot;, pch=20,
     main=&quot;AUC Test Distribution&quot;,
     xlab=&quot;Iteration&quot;, ylab=&quot;AUC&quot;)
abline(h=mean(test_aucs), col=&quot;blue&quot;, lwd=2, lty=2)
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col=&quot;green&quot;, lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col=&quot;green&quot;, lwd=2, lty=3)
legend(&quot;bottomright&quot;, 
       legend=c(&quot;AUC Values&quot;, &quot;Mean&quot;, &quot;95% CI Bounds&quot;),
       col=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code># Plot ROC curve with confidence intervals
suppressWarnings({
  plot(0:100/100, 0:100/100, type=&quot;l&quot;, lty=2, 
       xlab=&quot;False Positive Rate&quot;, ylab=&quot;True Positive Rate&quot;,
       main=&quot;ROC Curve - Linear Model&quot;)
  
  # Calculate average ROC curve with confidence intervals
  fpr_grid &lt;- seq(0, 1, length.out = 100)
  tpr_matrix &lt;- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))
  
  for(i in seq_along(performance_list)) {
    curve_i &lt;- performance_list[[i]]
    tpr_matrix[i,] &lt;- approx(curve_i@x.values[[1]], 
                            curve_i@y.values[[1]], 
                            xout = fpr_grid)$y
  }
  
  mean_tpr &lt;- colMeans(tpr_matrix, na.rm = TRUE)
  lines(fpr_grid, mean_tpr, col=&quot;red&quot;, lwd=2)
  
  # Add optimal threshold point
  opt_point_idx &lt;- which.min(abs(fpr_grid - mean(all_thresholds)))
  points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
         col=&quot;blue&quot;, pch=19, cex=1.5)
  
  # Add confidence interval
  ci_lower &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
  ci_upper &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
  lines(fpr_grid, ci_lower, col=&quot;gray&quot;, lty=2)
  lines(fpr_grid, ci_upper, col=&quot;gray&quot;, lty=2)
  
  # Add legend
  legend(&quot;bottomright&quot;, 
         legend=c(&quot;Random&quot;, &quot;Average ROC&quot;, &quot;95% CI&quot;, &quot;Optimal Threshold&quot;),
         col=c(&quot;black&quot;, &quot;red&quot;, &quot;gray&quot;, &quot;blue&quot;), 
         lty=c(2,1,2,NA), 
         pch=c(NA,NA,NA,19),
         lwd=c(1,2,1,NA))
})</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-6-2.png" width="672" /></p>
<pre class="r"><code># Load required libraries
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs &lt;- model.matrix(~ . - 1 - conversion, data = outcome_data)
y &lt;- as.numeric(as.character(outcome_data$conversion))


# Create parameter grid
grid &lt;- expand.grid(
  eta = seq(0.001, 0.1, by = 0.02),
  max_depth = seq(5, 7, by = 2),
  min_child_weight = seq(1, 1, by = 1),        
  subsample = seq(0.8, 1, by = 0.2),
  colsample_bytree = seq(0.8, 1, by = 0.2),
  lambda = seq(1, 1, by = 1),                
  alpha = seq(0, 0, by = 1),                  
  gamma = seq(0, 0, by = 0.1),               
  nrounds = seq(100, 500, by = 50)
)

# Sample grid points
conf_lev &lt;- .95
num_max &lt;- 5
n &lt;- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind &lt;- sample(nrow(grid), n, replace = FALSE)
rgrid &lt;- grid[ind, ]

# Set up parallel processing
nc &lt;- detectCores() - 1

# Validation phase
cat(&quot;\nPhase 1: Validation Phase\n&quot;)</code></pre>
<pre><code>## 
## Phase 1: Validation Phase</code></pre>
<pre class="r"><code>n_validations &lt;- 20
validation_results &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
 # cat(&quot;\nTesting parameter set&quot;, j, &quot;of&quot;, nrow(rgrid), &quot;\n&quot;)
  #cat(&quot;eta =&quot;, rgrid[j, &quot;eta&quot;], &quot;, nrounds =&quot;, rgrid[j, &quot;nrounds&quot;], &quot;\n&quot;)
  
  for (i in 1:n_validations) {
    # Create validation split
    idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
    train_x &lt;- xs[idx, ]
    train_y &lt;- y[idx]
    val_x &lt;- xs[-idx, ]
    val_y &lt;- y[-idx]
    
    prm &lt;- list(
      booster = &quot;gbtree&quot;,
      objective = &quot;binary:logistic&quot;,
      max_depth = rgrid[j, &quot;max_depth&quot;],
      eta = rgrid[j, &quot;eta&quot;],
      subsample = rgrid[j, &quot;subsample&quot;],
      colsample_bytree = rgrid[j, &quot;colsample_bytree&quot;],
      gamma = rgrid[j, &quot;gamma&quot;],
      min_child_weight = rgrid[j, &quot;min_child_weight&quot;],
      alpha = rgrid[j, &quot;alpha&quot;],
      lambda = rgrid[j, &quot;lambda&quot;],
      nthread = nc
    )
    
    dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
    mdl &lt;- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, &quot;nrounds&quot;],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p &lt;- predict(mdl, xgb.DMatrix(data = val_x))
    pred &lt;- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
    
    # Calculate Youden&#39;s J Statistic
    roc &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
    tpr &lt;- unlist(roc@y.values)
    fpr &lt;- unlist(roc@x.values)
    j_stats &lt;- tpr - fpr
    validation_j_stats[j, i] &lt;- max(j_stats)
  }
  
  #cat(&quot;Mean AUC:&quot;, mean(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;SD AUC:&quot;, sd(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;Mean J statistic:&quot;, mean(validation_j_stats[j,]), &quot;\n&quot;)
}

# Select best parameters based on validation AUC
best_params_idx &lt;- which.max(rowMeans(validation_results))
best_params &lt;- rgrid[best_params_idx,]
cat(&quot;\nBest parameters:\n&quot;)</code></pre>
<pre><code>## 
## Best parameters:</code></pre>
<pre class="r"><code>print(best_params)</code></pre>
<pre><code>##       eta max_depth min_child_weight subsample colsample_bytree lambda alpha
## 101 0.001         5                1       0.8                1      1     0
##     gamma nrounds
## 101     0     200</code></pre>
<pre class="r"><code># Run 100 tests with best parameters
cat(&quot;\nRunning 100 test iterations with best parameters...\n&quot;)</code></pre>
<pre><code>## 
## Running 100 test iterations with best parameters...</code></pre>
<pre class="r"><code>test_aucs &lt;- c()
test_j_stats &lt;- c()
confusion_matrices &lt;- list()
performance_list &lt;- list()
all_thresholds &lt;- c()                             

# Train final model with best parameters
best_params_list &lt;- as.list(best_params[-which(names(best_params) == &quot;nrounds&quot;)])
best_params_list$booster &lt;- &quot;gbtree&quot;
best_params_list$objective &lt;- &quot;binary:logistic&quot;
best_params_list$nthread &lt;- nc

for(i in 1:100) {
  #cat(&quot;\nIteration&quot;, i, &quot;of 100\n&quot;)       
  # Create test split
  idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
  train_x &lt;- xs[idx, ]
  train_y &lt;- y[idx]
  test_x &lt;- xs[-idx, ]
  test_y &lt;- y[-idx]
  
  # Train model
  dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
  mdl &lt;- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[[&quot;nrounds&quot;]],
    verbose = FALSE
  )
  
  # Get predictions
  p &lt;- predict(mdl, xgb.DMatrix(data = test_x))
  pred &lt;- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
  
  # Calculate ROC curve and store
  perf &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
  performance_list[[i]] &lt;- perf
  
  # Find optimal threshold using Youden&#39;s J statistic
  tpr &lt;- unlist(perf@y.values)
  fpr &lt;- unlist(perf@x.values)
  j_stats &lt;- tpr - fpr
  best_j_idx &lt;- which.max(j_stats)
  optimal_threshold &lt;- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] &lt;- optimal_threshold
  test_j_stats[i] &lt;- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class &lt;- ifelse(p &gt;= optimal_threshold, 1, 0)
  cm &lt;- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) &lt;- c(&quot;Pred 1&quot;, &quot;Pred 0&quot;)
  rownames(cm) &lt;- c(&quot;True 1&quot;, &quot;True 0&quot;)
  confusion_matrices[[i]] &lt;- cm
}

# Calculate average confusion matrix
avg_cm &lt;- Reduce(&#39;+&#39;, confusion_matrices) / length(confusion_matrices)

# Print final results
cat(&quot;\nTest Results over 100 iterations:\n&quot;)</code></pre>
<pre><code>## 
## Test Results over 100 iterations:</code></pre>
<pre class="r"><code>cat(&quot;Mean AUC:&quot;, mean(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## Mean AUC: 0.6797662</code></pre>
<pre class="r"><code>cat(&quot;SD AUC:&quot;, sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## SD AUC: 0.01172298</code></pre>
<pre class="r"><code>cat(&quot;Mean Youden&#39;s J:&quot;, mean(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Youden&#39;s J: 0.2797495</code></pre>
<pre class="r"><code>cat(&quot;SD Youden&#39;s J:&quot;, sd(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## SD Youden&#39;s J: 0.02058177</code></pre>
<pre class="r"><code>cat(&quot;Mean Optimal Threshold:&quot;, mean(all_thresholds), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Optimal Threshold: 0.5023184</code></pre>
<pre class="r"><code>cat(&quot;95% CI for AUC:&quot;, mean(test_aucs) - 1.96 * sd(test_aucs), 
    &quot;to&quot;, mean(test_aucs) + 1.96 * sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## 95% CI for AUC: 0.6567891 to 0.7027432</code></pre>
<pre class="r"><code>cat(&quot;\nAverage Confusion Matrix:\n&quot;)</code></pre>
<pre><code>## 
## Average Confusion Matrix:</code></pre>
<pre class="r"><code>print(avg_cm)</code></pre>
<pre><code>##         
##          Pred 1 Pred 0
##   True 1 518.79 247.29
##   True 0 281.77 427.87</code></pre>
<pre class="r"><code># Plotting AUC distribution - removed type=&quot;o&quot; to not connect dots
plot(test_aucs, col=&quot;red&quot;, pch=20,
     main=&quot;AUC Test Distribution&quot;,
     xlab=&quot;Iteration&quot;, ylab=&quot;AUC&quot;)
abline(h=mean(test_aucs), col=&quot;blue&quot;, lwd=2, lty=2)
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col=&quot;green&quot;, lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col=&quot;green&quot;, lwd=2, lty=3)
legend(&quot;bottomright&quot;, 
       legend=c(&quot;AUC Values&quot;, &quot;Mean&quot;, &quot;95% CI Bounds&quot;),
       col=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<pre class="r"><code># Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type=&quot;l&quot;, lty=2, 
     xlab=&quot;False Positive Rate&quot;, ylab=&quot;True Positive Rate&quot;,
     main=&quot;ROC Curve&quot;)

# Calculate average ROC curve with confidence intervals
fpr_grid &lt;- seq(0, 1, length.out = 100)
tpr_matrix &lt;- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i &lt;- performance_list[[i]]
  tpr_matrix[i,] &lt;- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr &lt;- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col=&quot;red&quot;, lwd=2)

# Add optimal threshold point
opt_point_idx &lt;- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col=&quot;blue&quot;, pch=19, cex=1.5)

# Add confidence interval
ci_lower &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col=&quot;gray&quot;, lty=2)
lines(fpr_grid, ci_upper, col=&quot;gray&quot;, lty=2)

# Add legend
legend(&quot;bottomright&quot;, 
       legend=c(&quot;Random&quot;, &quot;Average ROC&quot;, &quot;95% CI&quot;, &quot;Optimal Threshold&quot;),
       col=c(&quot;black&quot;, &quot;red&quot;, &quot;gray&quot;, &quot;blue&quot;), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-7-2.png" width="672" /></p>
<pre class="r"><code># Load required libraries
library(data.table)
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs &lt;- model.matrix(~ . - 1 - conversion, data = outcome_data)
y &lt;- as.numeric(as.character(outcome_data$conversion))

# Create parameter grid - only tune eta and nrounds
grid &lt;- expand.grid(
  eta = seq(0.001, 0.1, by = 0.01),
  nrounds = seq(50, 500, by = 50)
)

# Sample grid points
conf_lev &lt;- .95
num_max &lt;- 5
n &lt;- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind &lt;- sample(nrow(grid), n, replace = FALSE)
rgrid &lt;- grid[ind, ]

# Set up parallel processing
nc &lt;- detectCores() - 1

# Validation phase
cat(&quot;\nPhase 1: Validation Phase\n&quot;)</code></pre>
<pre><code>## 
## Phase 1: Validation Phase</code></pre>
<pre class="r"><code>n_validations &lt;- 20
validation_results &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats &lt;- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
  #cat(&quot;\nTesting parameter set&quot;, j, &quot;of&quot;, nrow(rgrid), &quot;\n&quot;)
  #cat(&quot;eta =&quot;, rgrid[j, &quot;eta&quot;], &quot;, nrounds =&quot;, rgrid[j, &quot;nrounds&quot;], &quot;\n&quot;)
  
  for (i in 1:n_validations) {
    # Create validation split
    idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
    train_x &lt;- xs[idx, ]
    train_y &lt;- y[idx]
    val_x &lt;- xs[-idx, ]
    val_y &lt;- y[-idx]
    
    prm &lt;- list(
      booster = &quot;gblinear&quot;,
      objective = &quot;binary:logistic&quot;,
      eta = rgrid[j, &quot;eta&quot;],
      nthread = nc
    )
    
    dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
    mdl &lt;- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, &quot;nrounds&quot;],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p &lt;- predict(mdl, xgb.DMatrix(data = val_x))
    pred &lt;- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
    
    # Calculate Youden&#39;s J Statistic
    roc &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
    tpr &lt;- unlist(roc@y.values)
    fpr &lt;- unlist(roc@x.values)
    j_stats &lt;- tpr - fpr
    validation_j_stats[j, i] &lt;- max(j_stats)
  }
  
  #cat(&quot;Mean AUC:&quot;, mean(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;SD AUC:&quot;, sd(validation_results[j,]), &quot;\n&quot;)
  #cat(&quot;Mean J statistic:&quot;, mean(validation_j_stats[j,]), &quot;\n&quot;)
}

# Select best parameters based on validation AUC
best_params_idx &lt;- which.max(rowMeans(validation_results))
best_params &lt;- rgrid[best_params_idx,]
cat(&quot;\nBest parameters:\n&quot;)</code></pre>
<pre><code>## 
## Best parameters:</code></pre>
<pre class="r"><code>print(best_params)</code></pre>
<pre><code>##      eta nrounds
## 73 0.021     400</code></pre>
<pre class="r"><code># Run X tests with best parameters
cat(&quot;\nRunning X test iterations with best parameters...\n&quot;)</code></pre>
<pre><code>## 
## Running X test iterations with best parameters...</code></pre>
<pre class="r"><code>test_aucs &lt;- c()
test_j_stats &lt;- c()
confusion_matrices &lt;- list()
performance_list &lt;- list()
all_thresholds &lt;- c()

# Train final model with best parameters
best_params_list &lt;- as.list(best_params[-which(names(best_params) == &quot;nrounds&quot;)])
best_params_list$booster &lt;- &quot;gblinear&quot;
best_params_list$objective &lt;- &quot;binary:logistic&quot;
best_params_list$nthread &lt;- nc

for(i in 1:100) {
  #cat(&quot;\nIteration&quot;, i, &quot;of 100\n&quot;)       
  # Create test split
  idx &lt;- unique(sample(nrow(xs), nrow(xs), T))
  train_x &lt;- xs[idx, ]
  train_y &lt;- y[idx]
  test_x &lt;- xs[-idx, ]
  test_y &lt;- y[-idx]
  
  # Train model
  dm_train &lt;- xgb.DMatrix(data = train_x, label = train_y)
  mdl &lt;- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[[&quot;nrounds&quot;]],
    verbose = FALSE
  )
  
  # Get predictions
  p &lt;- predict(mdl, xgb.DMatrix(data = test_x))
  pred &lt;- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] &lt;- performance(pred, &quot;auc&quot;)@y.values[[1]]
  
  # Calculate ROC curve and store
  perf &lt;- performance(pred, &quot;tpr&quot;, &quot;fpr&quot;)
  performance_list[[i]] &lt;- perf
  
  # Find optimal threshold using Youden&#39;s J statistic
  tpr &lt;- unlist(perf@y.values)
  fpr &lt;- unlist(perf@x.values)
  j_stats &lt;- tpr - fpr
  best_j_idx &lt;- which.max(j_stats)
  optimal_threshold &lt;- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] &lt;- optimal_threshold
  test_j_stats[i] &lt;- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class &lt;- ifelse(p &gt;= optimal_threshold, 1, 0)
  cm &lt;- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) &lt;- c(&quot;Pred 1&quot;, &quot;Pred 0&quot;)
  rownames(cm) &lt;- c(&quot;True 1&quot;, &quot;True 0&quot;)
  confusion_matrices[[i]] &lt;- cm
}

# Calculate average confusion matrix
avg_cm &lt;- Reduce(&#39;+&#39;, confusion_matrices) / length(confusion_matrices)

# Print final results
cat(&quot;\nTest Results over 100 iterations:\n&quot;)</code></pre>
<pre><code>## 
## Test Results over 100 iterations:</code></pre>
<pre class="r"><code>cat(&quot;Mean AUC:&quot;, mean(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## Mean AUC: 0.6828414</code></pre>
<pre class="r"><code>cat(&quot;SD AUC:&quot;, sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## SD AUC: 0.0119959</code></pre>
<pre class="r"><code>cat(&quot;Mean Youden&#39;s J:&quot;, mean(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Youden&#39;s J: 0.2827346</code></pre>
<pre class="r"><code>cat(&quot;SD Youden&#39;s J:&quot;, sd(test_j_stats), &quot;\n&quot;)</code></pre>
<pre><code>## SD Youden&#39;s J: 0.01971707</code></pre>
<pre class="r"><code>cat(&quot;Mean Optimal Threshold:&quot;, mean(all_thresholds), &quot;\n&quot;)</code></pre>
<pre><code>## Mean Optimal Threshold: 0.5115293</code></pre>
<pre class="r"><code>cat(&quot;95% CI for AUC:&quot;, mean(test_aucs) - 1.96 * sd(test_aucs), 
    &quot;to&quot;, mean(test_aucs) + 1.96 * sd(test_aucs), &quot;\n&quot;)</code></pre>
<pre><code>## 95% CI for AUC: 0.6593294 to 0.7063534</code></pre>
<pre class="r"><code>cat(&quot;\nAverage Confusion Matrix:\n&quot;)</code></pre>
<pre><code>## 
## Average Confusion Matrix:</code></pre>
<pre class="r"><code>print(avg_cm)</code></pre>
<pre><code>##         
##          Pred 1 Pred 0
##   True 1 525.37 245.12
##   True 0 282.12 424.92</code></pre>
<pre class="r"><code># Plotting AUC distribution - removed type=&quot;o&quot; to not connect dots
plot(test_aucs, col=&quot;red&quot;, pch=20,
     main=&quot;AUC Test Distribution&quot;,
     xlab=&quot;Iteration&quot;, ylab=&quot;AUC&quot;)
abline(h=mean(test_aucs), col=&quot;blue&quot;, lwd=2, lty=2)
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col=&quot;green&quot;, lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col=&quot;green&quot;, lwd=2, lty=3)
legend(&quot;bottomright&quot;, 
       legend=c(&quot;AUC Values&quot;, &quot;Mean&quot;, &quot;95% CI Bounds&quot;),
       col=c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<pre class="r"><code># Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type=&quot;l&quot;, lty=2, 
     xlab=&quot;False Positive Rate&quot;, ylab=&quot;True Positive Rate&quot;,
     main=&quot;ROC Curve&quot;)

# Calculate average ROC curve with confidence intervals
fpr_grid &lt;- seq(0, 1, length.out = 100)
tpr_matrix &lt;- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i &lt;- performance_list[[i]]
  tpr_matrix[i,] &lt;- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr &lt;- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col=&quot;red&quot;, lwd=2)

# Add optimal threshold point
opt_point_idx &lt;- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col=&quot;blue&quot;, pch=19, cex=1.5)

# Add confidence interval
ci_lower &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper &lt;- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col=&quot;gray&quot;, lty=2)
lines(fpr_grid, ci_upper, col=&quot;gray&quot;, lty=2)

# Add legend
legend(&quot;bottomright&quot;, 
       legend=c(&quot;Random&quot;, &quot;Average ROC&quot;, &quot;95% CI&quot;, &quot;Optimal Threshold&quot;),
       col=c(&quot;black&quot;, &quot;red&quot;, &quot;gray&quot;, &quot;blue&quot;), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))</code></pre>
<p><img src="xgboost_files/figure-html/unnamed-chunk-8-2.png" width="672" /></p>

<div id="rmd-source-code">---
title: "XGBoost Prediction Model"
output: html_document
---


```{r options, include=FALSE}
options(max.print=10000)
```

```{r}
library(data.table)   

outcome_data <- fread("predict_outcome.csv.gz")

# Filter out year*_team columns
year_cols <- grep("^year[0-9]+_team", names(outcome_data), value = TRUE)
outcome_data[, (year_cols) := NULL]
```

```{r}
# Function to check column variance and other potential issues
check_columns <- function(dt) {
  # Create a list to store results
  col_issues <- list(
    zero_var = character(),
    all_na = character(),
    perfect_cor = character(),
    character_cols = character()
  )
  
  # First, identify character columns (except my_id)
  for(col in names(dt)) {
    if(is.character(dt[[col]]) && col != "my_id") {
      col_issues$character_cols <- c(col_issues$character_cols, col)
    }
  }
  
  # Get numeric columns only
  numeric_cols <- names(dt)[sapply(dt, is.numeric)]
  numeric_cols <- setdiff(numeric_cols, "conversion")  # exclude target variable
  
  # Check each numeric column
  for(col in numeric_cols) {
    # Get column data without NAs
    col_data <- dt[[col]][!is.na(dt[[col]])]
    
    # Check for zero variance
    if(length(unique(col_data)) == 1) {
      col_issues$zero_var <- c(col_issues$zero_var, col)
      next
    }
    
    # Check for all NA
    if(all(is.na(dt[[col]]))) {
      col_issues$all_na <- c(col_issues$all_na, col)
    }
  }
  
  # Check correlations for remaining numeric columns
  remaining_cols <- setdiff(numeric_cols, 
                          unique(c(col_issues$zero_var, col_issues$all_na)))
  
  if(length(remaining_cols) > 1) {
    # Create correlation matrix
    cor_matrix <- cor(dt[, ..remaining_cols], use = "pairwise.complete.obs")
    
    # Find highly correlated pairs
    for(i in 1:(length(remaining_cols)-1)) {
      for(j in (i+1):length(remaining_cols)) {
        if(!is.na(cor_matrix[i,j]) && abs(cor_matrix[i,j]) > 0.9999) {
          col_issues$perfect_cor <- c(col_issues$perfect_cor, remaining_cols[j])
        }
      }
    }
  }
  
  return(col_issues)
}

# Find problematic columns
issues <- check_columns(outcome_data)

# Print summary of issues found
cat("Found the following issues:\n")
if(length(issues$character_cols) > 0) {
  cat("\nCharacter columns (excluding my_id):", paste(issues$character_cols, collapse=", "))
}
if(length(issues$zero_var) > 0) {
  cat("\nZero variance columns:", paste(issues$zero_var, collapse=", "))
}
if(length(issues$all_na) > 0) {
  cat("\nAll NA columns:", paste(issues$all_na, collapse=", "))
}
if(length(issues$perfect_cor) > 0) {
  cat("\nPerfectly correlated columns:", paste(unique(issues$perfect_cor), collapse=", "))
}

# Combine all problematic columns
problem_cols <- unique(c(issues$zero_var, issues$all_na, 
                        issues$perfect_cor, issues$character_cols))

# Remove problematic columns
if(length(problem_cols) > 0) {
  outcome_data[, (problem_cols) := NULL]
}

# Print summary of remaining columns
cat("\n\nRemoved", length(problem_cols), "problematic columns")
cat("\nRemaining columns:", ncol(outcome_data))
```




```{r}
# Load library and prepare data
#library(randomForest)
#rf_data <- copy(outcome_data)[, my_id := NULL]
#rf_data[, conversion := as.factor(conversion)]

# Run RF and get OOB AUC
#rf_model <- randomForest(conversion ~ ., data = rf_data, ntree = 100, importance = TRUE)
#pred_oob <- predict(rf_model, type = "prob")[,2]
#cat("\nOOB AUC:", as.numeric(performance(prediction(pred_oob, as.numeric(as.character(rf_data$conversion))), "auc")@y.values))

# Filter variables based on positive MDA
#mda_scores <- importance(rf_model)[, "MeanDecreaseAccuracy"]
#keep_vars <- unique(c(names(mda_scores[mda_scores > 0]), "my_id", "conversion"))
#outcome_data <- outcome_data[, .SD, .SDcols = keep_vars]

#cat("\nVariables kept:", length(keep_vars), "out of", ncol(rf_data) + 1)
```

```{r}
library(randomForest)
library(ROCR)  # Added this library

# Initialize variables for RF loop
rf_data <- copy(outcome_data)[, my_id := NULL]
rf_data[, conversion := as.factor(conversion)]
best_auc <- 0
previous_data <- NULL

# Iterative RF process for variable selection
while(TRUE) {
    # Run RF
    rf_model <- randomForest(conversion ~ ., data = rf_data, ntree = 100, importance = TRUE)
    pred_oob <- predict(rf_model, type = "prob")[,2]
    
    # Calculate OOB AUC using ROCR
    pred <- prediction(pred_oob, as.numeric(as.character(rf_data$conversion)))
    current_auc <- as.numeric(performance(pred, "auc")@y.values)
    
    cat("\nCurrent AUC:", round(current_auc, 4), "with", ncol(rf_data)-1, "variables")
    
    # Check if AUC dropped
    if(!is.null(previous_data) && current_auc < best_auc) {
        cat("\nAUC dropped, reverting to previous state")
        outcome_data <- previous_data
        break
    }
    
    # Update best and prepare for next iteration
    if(current_auc > best_auc) {
        best_auc <- current_auc
        previous_data <- copy(outcome_data)
    }
    
    # Filter variables based on positive MDA
    mda_scores <- importance(rf_model)[, "MeanDecreaseAccuracy"]
    keep_vars <- unique(c(names(mda_scores[mda_scores > 0]), "my_id", "conversion"))
    
    # Update data for next iteration
    outcome_data <- outcome_data[, .SD, .SDcols = keep_vars]
    rf_data <- copy(outcome_data)[, my_id := NULL]
    rf_data[, conversion := as.factor(conversion)]
}

```

```{r}
#kill my id
outcome_data$my_id <- NULL
```



```{r, warning=FALSE, message=FALSE}
# Run 100 tests with linear model
cat("\nRunning 100 test iterations with linear model...\n")
test_aucs <- c()
test_j_stats <- c()
confusion_matrices <- list()
performance_list <- list()
all_thresholds <- c()

# Convert data for linear model
model_data <- copy(outcome_data)
model_data[, conversion := as.numeric(as.character(conversion))]

# Run 100 tests with linear model
test_aucs <- c()
test_j_stats <- c()
confusion_matrices <- list()
performance_list <- list()
all_thresholds <- c()

# Convert data for linear model
model_data <- copy(outcome_data)
model_data[, conversion := as.numeric(as.character(conversion))]

for(i in 1:100) {
  # Create test split
  idx <- sample(1:nrow(model_data), size = floor(0.7 * nrow(model_data)))  # Changed sampling approach
  train_data <- model_data[idx, ]
  test_data <- model_data[-idx, ]
  
  # Train model
  mdl <- lm(conversion ~ ., data = train_data)
  
  # Get predictions and handle potential issues
  p <- predict(mdl, test_data)
  
  # Clean predictions
  p[is.na(p)] <- 0  # Handle NAs
  p[is.infinite(p)] <- 1  # Handle Inf
  p[p > 1] <- 1  # Bound predictions
  p[p < 0] <- 0
  
  # Convert predictions and actual values to numeric vectors
  pred_values <- as.numeric(p)
  actual_values <- as.numeric(test_data$conversion)
  
  # Check for any remaining issues
  if(any(is.na(pred_values)) || any(is.infinite(pred_values))) {
    cat("Warning: Invalid predictions in iteration", i, "\n")
    next
  }
  
  # Create ROCR prediction object with error handling
  tryCatch({
    pred <- prediction(pred_values, actual_values)
    
    # Calculate AUC
    perf_auc <- performance(pred, "auc")
    test_aucs[i] <- perf_auc@y.values[[1]]
    
    # Calculate ROC curve
    perf <- performance(pred, "tpr", "fpr")
    performance_list[[i]] <- perf
    
    # Find optimal threshold using Youden's J statistic
    tpr <- unlist(perf@y.values)
    fpr <- unlist(perf@x.values)
    j_stats <- tpr - fpr
    best_j_idx <- which.max(j_stats)
    optimal_threshold <- unlist(perf@alpha.values)[best_j_idx]
    all_thresholds[i] <- optimal_threshold
    test_j_stats[i] <- j_stats[best_j_idx]
    
    # Create confusion matrix
    pred_class <- ifelse(pred_values >= optimal_threshold, 1, 0)
    cm <- table(factor(actual_values, levels=c(1,0)), 
               factor(pred_class, levels=c(1,0)))
    colnames(cm) <- c("Pred 1", "Pred 0")
    rownames(cm) <- c("True 1", "True 0")
    confusion_matrices[[i]] <- cm
  }, error = function(e) {
    cat("Error in iteration", i, ":", e$message, "\n")
  })
}

# Calculate average confusion matrix
avg_cm <- Reduce('+', confusion_matrices) / length(confusion_matrices)

# Print final results
cat("\nTest Results over 100 iterations:\n")
cat("Mean AUC:", mean(test_aucs), "\n")
cat("SD AUC:", sd(test_aucs), "\n")
cat("Mean Youden's J:", mean(test_j_stats), "\n")
cat("SD Youden's J:", sd(test_j_stats), "\n")
cat("Mean Optimal Threshold:", mean(all_thresholds), "\n")
cat("95% CI for AUC:", mean(test_aucs) - 1.96 * sd(test_aucs), 
    "to", mean(test_aucs) + 1.96 * sd(test_aucs), "\n")
cat("\nAverage Confusion Matrix:\n")
print(avg_cm)

# Plotting AUC distribution - removed type="o" to not connect dots
plot(test_aucs, col="red", pch=20,
     main="AUC Test Distribution",
     xlab="Iteration", ylab="AUC")
abline(h=mean(test_aucs), col="blue", lwd=2, lty=2)
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
legend("bottomright", 
       legend=c("AUC Values", "Mean", "95% CI Bounds"),
       col=c("red", "blue", "green"),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))

# Plot ROC curve with confidence intervals
suppressWarnings({
  plot(0:100/100, 0:100/100, type="l", lty=2, 
       xlab="False Positive Rate", ylab="True Positive Rate",
       main="ROC Curve - Linear Model")
  
  # Calculate average ROC curve with confidence intervals
  fpr_grid <- seq(0, 1, length.out = 100)
  tpr_matrix <- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))
  
  for(i in seq_along(performance_list)) {
    curve_i <- performance_list[[i]]
    tpr_matrix[i,] <- approx(curve_i@x.values[[1]], 
                            curve_i@y.values[[1]], 
                            xout = fpr_grid)$y
  }
  
  mean_tpr <- colMeans(tpr_matrix, na.rm = TRUE)
  lines(fpr_grid, mean_tpr, col="red", lwd=2)
  
  # Add optimal threshold point
  opt_point_idx <- which.min(abs(fpr_grid - mean(all_thresholds)))
  points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
         col="blue", pch=19, cex=1.5)
  
  # Add confidence interval
  ci_lower <- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
  ci_upper <- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
  lines(fpr_grid, ci_lower, col="gray", lty=2)
  lines(fpr_grid, ci_upper, col="gray", lty=2)
  
  # Add legend
  legend("bottomright", 
         legend=c("Random", "Average ROC", "95% CI", "Optimal Threshold"),
         col=c("black", "red", "gray", "blue"), 
         lty=c(2,1,2,NA), 
         pch=c(NA,NA,NA,19),
         lwd=c(1,2,1,NA))
})
```




```{r, warning=FALSE, message=FALSE}                        
# Load required libraries
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs <- model.matrix(~ . - 1 - conversion, data = outcome_data)
y <- as.numeric(as.character(outcome_data$conversion))


# Create parameter grid
grid <- expand.grid(
  eta = seq(0.001, 0.1, by = 0.02),
  max_depth = seq(5, 7, by = 2),
  min_child_weight = seq(1, 1, by = 1),        
  subsample = seq(0.8, 1, by = 0.2),
  colsample_bytree = seq(0.8, 1, by = 0.2),
  lambda = seq(1, 1, by = 1),                
  alpha = seq(0, 0, by = 1),                  
  gamma = seq(0, 0, by = 0.1),               
  nrounds = seq(100, 500, by = 50)
)

# Sample grid points
conf_lev <- .95
num_max <- 5
n <- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind <- sample(nrow(grid), n, replace = FALSE)
rgrid <- grid[ind, ]

# Set up parallel processing
nc <- detectCores() - 1

# Validation phase
cat("\nPhase 1: Validation Phase\n")
n_validations <- 20
validation_results <- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats <- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
 # cat("\nTesting parameter set", j, "of", nrow(rgrid), "\n")
  #cat("eta =", rgrid[j, "eta"], ", nrounds =", rgrid[j, "nrounds"], "\n")
  
  for (i in 1:n_validations) {
    # Create validation split
    idx <- unique(sample(nrow(xs), nrow(xs), T))
    train_x <- xs[idx, ]
    train_y <- y[idx]
    val_x <- xs[-idx, ]
    val_y <- y[-idx]
    
    prm <- list(
      booster = "gbtree",
      objective = "binary:logistic",
      max_depth = rgrid[j, "max_depth"],
      eta = rgrid[j, "eta"],
      subsample = rgrid[j, "subsample"],
      colsample_bytree = rgrid[j, "colsample_bytree"],
      gamma = rgrid[j, "gamma"],
      min_child_weight = rgrid[j, "min_child_weight"],
      alpha = rgrid[j, "alpha"],
      lambda = rgrid[j, "lambda"],
      nthread = nc
    )
    
    dm_train <- xgb.DMatrix(data = train_x, label = train_y)
    mdl <- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, "nrounds"],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p <- predict(mdl, xgb.DMatrix(data = val_x))
    pred <- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] <- performance(pred, "auc")@y.values[[1]]
    
    # Calculate Youden's J Statistic
    roc <- performance(pred, "tpr", "fpr")
    tpr <- unlist(roc@y.values)
    fpr <- unlist(roc@x.values)
    j_stats <- tpr - fpr
    validation_j_stats[j, i] <- max(j_stats)
  }
  
  #cat("Mean AUC:", mean(validation_results[j,]), "\n")
  #cat("SD AUC:", sd(validation_results[j,]), "\n")
  #cat("Mean J statistic:", mean(validation_j_stats[j,]), "\n")
}

# Select best parameters based on validation AUC
best_params_idx <- which.max(rowMeans(validation_results))
best_params <- rgrid[best_params_idx,]
cat("\nBest parameters:\n")
print(best_params)

# Run 100 tests with best parameters
cat("\nRunning 100 test iterations with best parameters...\n")
test_aucs <- c()
test_j_stats <- c()
confusion_matrices <- list()
performance_list <- list()
all_thresholds <- c()                             

# Train final model with best parameters
best_params_list <- as.list(best_params[-which(names(best_params) == "nrounds")])
best_params_list$booster <- "gbtree"
best_params_list$objective <- "binary:logistic"
best_params_list$nthread <- nc

for(i in 1:100) {
  #cat("\nIteration", i, "of 100\n")       
  # Create test split
  idx <- unique(sample(nrow(xs), nrow(xs), T))
  train_x <- xs[idx, ]
  train_y <- y[idx]
  test_x <- xs[-idx, ]
  test_y <- y[-idx]
  
  # Train model
  dm_train <- xgb.DMatrix(data = train_x, label = train_y)
  mdl <- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[["nrounds"]],
    verbose = FALSE
  )
  
  # Get predictions
  p <- predict(mdl, xgb.DMatrix(data = test_x))
  pred <- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] <- performance(pred, "auc")@y.values[[1]]
  
  # Calculate ROC curve and store
  perf <- performance(pred, "tpr", "fpr")
  performance_list[[i]] <- perf
  
  # Find optimal threshold using Youden's J statistic
  tpr <- unlist(perf@y.values)
  fpr <- unlist(perf@x.values)
  j_stats <- tpr - fpr
  best_j_idx <- which.max(j_stats)
  optimal_threshold <- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] <- optimal_threshold
  test_j_stats[i] <- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class <- ifelse(p >= optimal_threshold, 1, 0)
  cm <- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) <- c("Pred 1", "Pred 0")
  rownames(cm) <- c("True 1", "True 0")
  confusion_matrices[[i]] <- cm
}

# Calculate average confusion matrix
avg_cm <- Reduce('+', confusion_matrices) / length(confusion_matrices)

# Print final results
cat("\nTest Results over 100 iterations:\n")
cat("Mean AUC:", mean(test_aucs), "\n")
cat("SD AUC:", sd(test_aucs), "\n")
cat("Mean Youden's J:", mean(test_j_stats), "\n")
cat("SD Youden's J:", sd(test_j_stats), "\n")
cat("Mean Optimal Threshold:", mean(all_thresholds), "\n")
cat("95% CI for AUC:", mean(test_aucs) - 1.96 * sd(test_aucs), 
    "to", mean(test_aucs) + 1.96 * sd(test_aucs), "\n")
cat("\nAverage Confusion Matrix:\n")
print(avg_cm)

# Plotting AUC distribution - removed type="o" to not connect dots
plot(test_aucs, col="red", pch=20,
     main="AUC Test Distribution",
     xlab="Iteration", ylab="AUC")
abline(h=mean(test_aucs), col="blue", lwd=2, lty=2)
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
legend("bottomright", 
       legend=c("AUC Values", "Mean", "95% CI Bounds"),
       col=c("red", "blue", "green"),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))


# Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type="l", lty=2, 
     xlab="False Positive Rate", ylab="True Positive Rate",
     main="ROC Curve")

# Calculate average ROC curve with confidence intervals
fpr_grid <- seq(0, 1, length.out = 100)
tpr_matrix <- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i <- performance_list[[i]]
  tpr_matrix[i,] <- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr <- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col="red", lwd=2)

# Add optimal threshold point
opt_point_idx <- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col="blue", pch=19, cex=1.5)

# Add confidence interval
ci_lower <- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper <- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col="gray", lty=2)
lines(fpr_grid, ci_upper, col="gray", lty=2)

# Add legend
legend("bottomright", 
       legend=c("Random", "Average ROC", "95% CI", "Optimal Threshold"),
       col=c("black", "red", "gray", "blue"), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))
```


```{r, warning=FALSE, message=FALSE}
# Load required libraries
library(data.table)
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs <- model.matrix(~ . - 1 - conversion, data = outcome_data)
y <- as.numeric(as.character(outcome_data$conversion))

# Create parameter grid - only tune eta and nrounds
grid <- expand.grid(
  eta = seq(0.001, 0.1, by = 0.01),
  nrounds = seq(50, 500, by = 50)
)

# Sample grid points
conf_lev <- .95
num_max <- 5
n <- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind <- sample(nrow(grid), n, replace = FALSE)
rgrid <- grid[ind, ]

# Set up parallel processing
nc <- detectCores() - 1

# Validation phase
cat("\nPhase 1: Validation Phase\n")
n_validations <- 20
validation_results <- matrix(nrow = nrow(rgrid), ncol = n_validations)
validation_j_stats <- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
  #cat("\nTesting parameter set", j, "of", nrow(rgrid), "\n")
  #cat("eta =", rgrid[j, "eta"], ", nrounds =", rgrid[j, "nrounds"], "\n")
  
  for (i in 1:n_validations) {
    # Create validation split
    idx <- unique(sample(nrow(xs), nrow(xs), T))
    train_x <- xs[idx, ]
    train_y <- y[idx]
    val_x <- xs[-idx, ]
    val_y <- y[-idx]
    
    prm <- list(
      booster = "gblinear",
      objective = "binary:logistic",
      eta = rgrid[j, "eta"],
      nthread = nc
    )
    
    dm_train <- xgb.DMatrix(data = train_x, label = train_y)
    mdl <- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, "nrounds"],
      verbose = FALSE
    )
    
    # Get predictions and ROC metrics
    p <- predict(mdl, xgb.DMatrix(data = val_x))
    pred <- prediction(p, val_y)
    
    # Calculate AUC
    validation_results[j, i] <- performance(pred, "auc")@y.values[[1]]
    
    # Calculate Youden's J Statistic
    roc <- performance(pred, "tpr", "fpr")
    tpr <- unlist(roc@y.values)
    fpr <- unlist(roc@x.values)
    j_stats <- tpr - fpr
    validation_j_stats[j, i] <- max(j_stats)
  }
  
  #cat("Mean AUC:", mean(validation_results[j,]), "\n")
  #cat("SD AUC:", sd(validation_results[j,]), "\n")
  #cat("Mean J statistic:", mean(validation_j_stats[j,]), "\n")
}

# Select best parameters based on validation AUC
best_params_idx <- which.max(rowMeans(validation_results))
best_params <- rgrid[best_params_idx,]
cat("\nBest parameters:\n")
print(best_params)

# Run X tests with best parameters
cat("\nRunning X test iterations with best parameters...\n")
test_aucs <- c()
test_j_stats <- c()
confusion_matrices <- list()
performance_list <- list()
all_thresholds <- c()

# Train final model with best parameters
best_params_list <- as.list(best_params[-which(names(best_params) == "nrounds")])
best_params_list$booster <- "gblinear"
best_params_list$objective <- "binary:logistic"
best_params_list$nthread <- nc

for(i in 1:100) {
  #cat("\nIteration", i, "of 100\n")       
  # Create test split
  idx <- unique(sample(nrow(xs), nrow(xs), T))
  train_x <- xs[idx, ]
  train_y <- y[idx]
  test_x <- xs[-idx, ]
  test_y <- y[-idx]
  
  # Train model
  dm_train <- xgb.DMatrix(data = train_x, label = train_y)
  mdl <- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[["nrounds"]],
    verbose = FALSE
  )
  
  # Get predictions
  p <- predict(mdl, xgb.DMatrix(data = test_x))
  pred <- prediction(p, test_y)
  
  # Calculate AUC
  test_aucs[i] <- performance(pred, "auc")@y.values[[1]]
  
  # Calculate ROC curve and store
  perf <- performance(pred, "tpr", "fpr")
  performance_list[[i]] <- perf
  
  # Find optimal threshold using Youden's J statistic
  tpr <- unlist(perf@y.values)
  fpr <- unlist(perf@x.values)
  j_stats <- tpr - fpr
  best_j_idx <- which.max(j_stats)
  optimal_threshold <- unlist(perf@alpha.values)[best_j_idx]
  all_thresholds[i] <- optimal_threshold
  test_j_stats[i] <- j_stats[best_j_idx]
  
  # Create confusion matrix with optimal threshold (1-0 order with TP in top left)
  pred_class <- ifelse(p >= optimal_threshold, 1, 0)
  cm <- table(factor(test_y, levels=c(1,0)), 
             factor(pred_class, levels=c(1,0)))
  colnames(cm) <- c("Pred 1", "Pred 0")
  rownames(cm) <- c("True 1", "True 0")
  confusion_matrices[[i]] <- cm
}

# Calculate average confusion matrix
avg_cm <- Reduce('+', confusion_matrices) / length(confusion_matrices)

# Print final results
cat("\nTest Results over 100 iterations:\n")
cat("Mean AUC:", mean(test_aucs), "\n")
cat("SD AUC:", sd(test_aucs), "\n")
cat("Mean Youden's J:", mean(test_j_stats), "\n")
cat("SD Youden's J:", sd(test_j_stats), "\n")
cat("Mean Optimal Threshold:", mean(all_thresholds), "\n")
cat("95% CI for AUC:", mean(test_aucs) - 1.96 * sd(test_aucs), 
    "to", mean(test_aucs) + 1.96 * sd(test_aucs), "\n")
cat("\nAverage Confusion Matrix:\n")
print(avg_cm)

# Plotting AUC distribution - removed type="o" to not connect dots
plot(test_aucs, col="red", pch=20,
     main="AUC Test Distribution",
     xlab="Iteration", ylab="AUC")
abline(h=mean(test_aucs), col="blue", lwd=2, lty=2)
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
legend("bottomright", 
       legend=c("AUC Values", "Mean", "95% CI Bounds"),
       col=c("red", "blue", "green"),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))


# Plot ROC curve with confidence intervals
plot(0:100/100, 0:100/100, type="l", lty=2, 
     xlab="False Positive Rate", ylab="True Positive Rate",
     main="ROC Curve")

# Calculate average ROC curve with confidence intervals
fpr_grid <- seq(0, 1, length.out = 100)
tpr_matrix <- matrix(NA, nrow = length(performance_list), ncol = length(fpr_grid))

for(i in seq_along(performance_list)) {
  curve_i <- performance_list[[i]]
  tpr_matrix[i,] <- approx(curve_i@x.values[[1]], 
                          curve_i@y.values[[1]], 
                          xout = fpr_grid)$y
}

mean_tpr <- colMeans(tpr_matrix, na.rm = TRUE)
lines(fpr_grid, mean_tpr, col="red", lwd=2)

# Add optimal threshold point
opt_point_idx <- which.min(abs(fpr_grid - mean(all_thresholds)))
points(fpr_grid[opt_point_idx], mean_tpr[opt_point_idx], 
       col="blue", pch=19, cex=1.5)

# Add confidence interval
ci_lower <- apply(tpr_matrix, 2, function(x) quantile(x, 0.025, na.rm=TRUE))
ci_upper <- apply(tpr_matrix, 2, function(x) quantile(x, 0.975, na.rm=TRUE))
lines(fpr_grid, ci_lower, col="gray", lty=2)
lines(fpr_grid, ci_upper, col="gray", lty=2)

# Add legend
legend("bottomright", 
       legend=c("Random", "Average ROC", "95% CI", "Optimal Threshold"),
       col=c("black", "red", "gray", "blue"), 
       lty=c(2,1,2,NA), 
       pch=c(NA,NA,NA,19),
       lwd=c(1,2,1,NA))
```

</div>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("xgboost.Rmd");
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
