---
title: "Heckman Selection Model Analysis"
output: html_document
---

```{r options, include=FALSE}
options(max.print=10000)
```

```{r}
library(data.table)
outcome_data <- fread("predict_outcome.csv.gz")
select_data <- fread("predict_select.csv.gz")
```

```{r}
select_data[, attempt := as.numeric(as.character(attempt))]
```

```{r}
library(data.table)
library(xgboost)
library(ROCR)
library(parallel)

# Prepare the XGBoost matrices
xs <- model.matrix(~ . - 1 - attempt - my_id, data = select_data)
y <- as.numeric(as.character(select_data$attempt))


# Create parameter grid
grid <- expand.grid(
  eta = seq(0.001, 0.03, by = 0.01),
  max_depth = seq(5, 5, by = 2),
  min_child_weight = seq(1, 1, by = 1),        
  subsample = seq(1, 1, by = 0.2),
  colsample_bytree = seq(1, 1, by = 0.2),
  lambda = seq(1, 1, by = 1),                
  alpha = seq(0, 0, by = 1),                  
  gamma = seq(0, 0, by = 0.1),               
  nrounds = seq(100, 250, by = 50)
)


# Sample grid points
conf_lev <- .95
num_max <- 5
n <- ceiling(log(1-conf_lev)/log(1-num_max/nrow(grid)))
ind <- sample(nrow(grid), n, replace = FALSE)
rgrid <- grid[ind, ]

# Set up parallel processing
nc <- detectCores() - 1

# Calculate scale_pos_weight for imbalanced dataset
scale_pos_weight <- sum(y == 0) / sum(y == 1)

# Validation phase
#cat("\nPhase 1: Validation Phase\n")
n_validations <- 1
validation_results <- matrix(nrow = nrow(rgrid), ncol = n_validations)

for (j in 1:nrow(rgrid)) {
  #cat("\nTesting parameter set", j, "of", nrow(rgrid), "\n")
  
  for (i in 1:n_validations) {
    #cat("\nValidation iteration", i, "of", n_validations, "\n")             
    # Create validation split
    idx <- unique(sample(nrow(xs), nrow(xs), TRUE))
    train_x <- xs[idx, ]
    train_y <- y[idx]
    val_x <- xs[-idx, ]
    val_y <- y[-idx]
    
    prm <- list(
      booster = "gbtree",
      objective = "binary:logistic",
      max_depth = rgrid[j, "max_depth"],
      eta = rgrid[j, "eta"],
      subsample = rgrid[j, "subsample"],
      colsample_bytree = rgrid[j, "colsample_bytree"],
      gamma = rgrid[j, "gamma"],
      min_child_weight = rgrid[j, "min_child_weight"],
      alpha = rgrid[j, "alpha"],
      lambda = rgrid[j, "lambda"],
      scale_pos_weight = scale_pos_weight,
      nthread = nc
    )
    
    dm_train <- xgb.DMatrix(data = train_x, label = train_y)
    mdl <- xgb.train(
      params = prm,
      data = dm_train,
      nrounds = rgrid[j, "nrounds"],
      verbose = FALSE
    )
    
    p <- predict(mdl, xgb.DMatrix(data = val_x))
    pred <- prediction(p, val_y)
    validation_results[j, i] <- performance(pred, "auc")@y.values[[1]]
  }
}

# Run 100 tests with best parameters
cat("\nRunning X test iterations with best parameters...\n")
test_aucs <- c()

best_params_idx <- which.max(rowMeans(validation_results))
best_params <- rgrid[best_params_idx,]

# Train final model with best parameters
best_params_list <- as.list(best_params[-which(names(best_params) == "nrounds")])
best_params_list$booster <- "gbtree"
best_params_list$objective <- "binary:logistic"
best_params_list$scale_pos_weight <- scale_pos_weight
best_params_list$nthread <- nc

for(i in 1:20) {
  # Create test split
  idx <- unique(sample(nrow(xs), nrow(xs), T))
  train_x <- xs[idx, ]
  train_y <- y[idx]
  test_x <- xs[-idx, ]
  test_y <- y[-idx]
  
  # Train model on full unbalanced dataset
  dm_train <- xgb.DMatrix(data = train_x, label = train_y)
  mdl <- xgb.train(
    params = best_params_list,
    data = dm_train,
    nrounds = best_params[["nrounds"]],
    verbose = FALSE
  )
  
  # Test on unbalanced test set
  p <- predict(mdl, xgb.DMatrix(data = test_x))
  pred <- prediction(p, test_y)
  test_aucs[i] <- performance(pred, "auc")@y.values[[1]]
}
# Print results
cat("\nTest Results over 100 iterations:\n")
cat("Mean AUC:", mean(test_aucs), "\n")
cat("SD AUC:", sd(test_aucs), "\n")
cat("95% CI:", mean(test_aucs) - 1.96 * sd(test_aucs), 
    "to", mean(test_aucs) + 1.96 * sd(test_aucs), "\n")

# Plotting AUC distribution
plot(test_aucs, col="red", pch=20,
     main="AUC Test Distribution",
     xlab="Iteration", ylab="AUC")
abline(h=mean(test_aucs), col="blue", lwd=2, lty=2)  # Add this line to show mean
abline(h=mean(test_aucs) - 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
abline(h=mean(test_aucs) + 1.96 * sd(test_aucs), col="green", lwd=2, lty=3)
legend("bottomright", 
       legend=c("AUC Values", "Mean", "95% CI Bounds"),
       col=c("red", "blue", "green"),
       lty=c(NA, 2, 3),
       pch=c(20, NA, NA))

# Now train final model on full data for z scores
dm_full <- xgb.DMatrix(data = xs, label = y)
final_model <- xgb.train(
  params = best_params_list,
  data = dm_full,
  nrounds = best_params[["nrounds"]],
  verbose = FALSE
)

# Get probability predictions (z) for ALL data
z <- predict(final_model, xgb.DMatrix(data = xs))
```


```{r}
# Calculate residuals for XGBoost predictions
y <- as.numeric(as.character(select_data$attempt))
residuals <- y - z

# Histogram of residuals
hist(residuals, main="Distribution of XGBoost Model Residuals", xlab="Residual", breaks=100)
```

```{r}
# plot out the z values\
plot(density(z), 
     main = "Density of Z Predictions",
     xlab = "Predicted Probability of Attempt",
     ylab = "Density")
```

```{r}
# Calculate GIMR (lambda) This is Generalized inverse mills ratio
GIMR <- dnorm(qnorm(z)) / (1 - pnorm(qnorm(z)))

# Add GIMR to the data
select_data[, GIMR := GIMR]

# Print variable importa
```

```{r}
# Create a data.table with just my_id and GIMR from select_data
GIMR_dt <- data.table(my_id = select_data$my_id, GIMR = GIMR)

# Add GIMR to outcome_data by matching on my_id
outcome_data[GIMR_dt, GIMR := i.GIMR, on = "my_id"]
```

```{r}
# Existing code
outcome_data <- outcome_data[, my_id := NULL]
outcome_data[, yardline_31_40 := NULL]
outcome_data[, year2022_team_CLE := NULL] # tied for most attempts with 31

# Remove all columns with "_present" in the name
present_cols <- grep("_present", names(outcome_data), value = TRUE)
for (col in present_cols) {
  outcome_data[, (col) := NULL]
}
#attendance_pct and total
outcome_data[, attendance_pct := NULL]
outcome_data[, attendance_raw := NULL]
#and toital_line
outcome_data[, vegas_wp_posteam := NULL]
```


```{r}
outcome_data[, conversion := as.numeric(as.character(conversion))]
# Then run OLS with GIMR correction
ols_model <- lm(conversion ~  ., data = outcome_data)
```

```{r}
library(sandwich)
library(lmtest)

# Get HC0-adjusted t-values and p-values
robust_test <- coeftest(ols_model, vcov = vcovHC(ols_model, type = "HC0"))
t_stats <- robust_test[, "t value"]
p_values <- robust_test[, "Pr(>|t|)"]

# Function to add significance stars
get_stars <- function(p) {
    if (p <= 0.01) return("***")
    if (p <= 0.05) return("**")
    if (p <= 0.1) return("*")
    if (p <= 0.15) return(".")
    return("")
}

# Maximum width for variable names
name_width <- 60

# Print header with alignment
cat(sprintf("%-*s  %10s  %10s  %4s\n", name_width, "Variable", "t-value", "p-value", "sig"))
cat(sprintf("%-*s  %10s  %10s  %4s\n", name_width, "---------", "-------", "-------", "----"))

# Loop through and print values
for (i in 1:length(t_stats)) {
    var_name <- rownames(robust_test)[i]
    # Truncate name if too long
    if (nchar(var_name) > name_width) {
        var_name <- paste0(substr(var_name, 1, name_width-3), "...")
    }
    cat(sprintf("%-*s  %10.4f  %10.4f  %4s\n", 
                name_width, var_name, 
                t_stats[i], p_values[i],
                get_stars(p_values[i])))
}

cat("\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 '.' 0.15")

r_squared <- summary(ols_model)$adj.r.squared
r_squared
```


```{r}
# Create a copy of outcome_data without GIMR
outcome_data_no_gimr <- copy(outcome_data)
outcome_data_no_gimr[, GIMR := NULL]
outcome_data_no_gimr[, my_id := NULL]

# Run OLS without GIMR correction
ols_model_no_gimr <- lm(conversion ~ ., data = outcome_data_no_gimr)

# Get HC0-adjusted t-values and p-values
robust_test_no_gimr <- coeftest(ols_model_no_gimr, vcov = vcovHC(ols_model_no_gimr, type = "HC0"))
t_stats_no_gimr <- robust_test_no_gimr[, "t value"]
p_values_no_gimr <- robust_test_no_gimr[, "Pr(>|t|)"]

# Print header with alignment
cat(sprintf("%-*s  %10s  %10s  %4s\n", name_width, "Variable", "t-value", "p-value", "sig"))
cat(sprintf("%-*s  %10s  %10s  %4s\n", name_width, "---------", "-------", "-------", "----"))

# Loop through and print values
for (i in 1:length(t_stats_no_gimr)) {
    var_name <- rownames(robust_test_no_gimr)[i]
    # Truncate name if too long
    if (nchar(var_name) > name_width) {
        var_name <- paste0(substr(var_name, 1, name_width-3), "...")
    }
    cat(sprintf("%-*s  %10.4f  %10.4f  %4s\n", 
                name_width, var_name, 
                t_stats_no_gimr[i], p_values_no_gimr[i],
                get_stars(p_values_no_gimr[i])))
}

cat("\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 '.' 0.15")

```

```{r}
# the r squard value
r_squared_no_gimr <- summary(ols_model_no_gimr)$adj.r.squared
r_squared_no_gimr

```


```{r}
# Load the car package which has the vif function
library(car)

# Calculate VIFs for the model with GIMR
vifs <- vif(ols_model)

# Filter to show only VIFs over 5
high_vifs <- vifs[vifs > 5]
if(length(high_vifs) > 0) {
  cat("\nVariables with VIF > 5 (with GIMR):\n")
  print(high_vifs)
} else {
  cat("\nNo variables with VIF > 5 found in the model with GIMR\n")
}

# Calculate VIFs for the model without GIMR
vifs_no_gimr <- vif(ols_model_no_gimr)

# Filter to show only VIFs over 5
high_vifs_no_gimr <- vifs_no_gimr[vifs_no_gimr > 5]
if(length(high_vifs_no_gimr) > 0) {
  cat("\nVariables with VIF > 5 (without GIMR):\n")
  print(high_vifs_no_gimr)
} else {
  cat("\nNo variables with VIF > 5 found in the model without GIMR\n")
}
```
#########################################

```{r}
# Original code up to where the model building starts remains the same
# After you've added GIMR to outcome_data by matching on my_id

# Create copies of outcome_data for different models
outcome_data_player <- copy(outcome_data)
outcome_data_starter <- copy(outcome_data)
outcome_data_player_no_gimr <- copy(outcome_data)
outcome_data_starter_no_gimr <- copy(outcome_data)

# Remove specific columns as in original code
for (dt in list(outcome_data_player, outcome_data_starter, 
                outcome_data_player_no_gimr, outcome_data_starter_no_gimr)) {
  dt[, my_id := NULL]
  dt[, yardline_31_40 := NULL]
  dt[, year2022_team_CLE := NULL] # tied for most attempts with 31
  
  # Remove attendance variables
  dt[, attendance_pct := NULL]
  dt[, attendance_raw := NULL]
  dt[, vegas_wp_posteam := NULL]
}

# For player models, remove starter columns
player_cols <- grep("^starter_", names(outcome_data_player), value = TRUE)
for (col in player_cols) {
  outcome_data_player[, (col) := NULL]
  outcome_data_player_no_gimr[, (col) := NULL]
}

# For starter models, remove player columns
starter_cols <- grep("^(offense|defense)_player_", names(outcome_data_starter), value = TRUE)
for (col in starter_cols) {
  outcome_data_starter[, (col) := NULL]
  outcome_data_starter_no_gimr[, (col) := NULL]
}

# Remove GIMR from no_gimr models
outcome_data_player_no_gimr[, GIMR := NULL]
outcome_data_starter_no_gimr[, GIMR := NULL]

# Ensure conversion is numeric
for (dt in list(outcome_data_player, outcome_data_starter, 
                outcome_data_player_no_gimr, outcome_data_starter_no_gimr)) {
  dt[, conversion := as.numeric(as.character(conversion))]
}

# MODEL 1: Player model with GIMR
ols_model_player <- lm(conversion ~ ., data = outcome_data_player)

# MODEL 2: Starter model with GIMR
ols_model_starter <- lm(conversion ~ ., data = outcome_data_starter)

# MODEL 3: Player model without GIMR
ols_model_player_no_gimr <- lm(conversion ~ ., data = outcome_data_player_no_gimr)

# MODEL 4: Starter model without GIMR
ols_model_starter_no_gimr <- lm(conversion ~ ., data = outcome_data_starter_no_gimr)

# Function to analyze and print model results
analyze_model <- function(model, model_name) {
  library(sandwich)
  library(lmtest)
  
  # Get HC0-adjusted t-values and p-values
  robust_test <- coeftest(model, vcov = vcovHC(model, type = "HC0"))
  t_stats <- robust_test[, "t value"]
  p_values <- robust_test[, "Pr(>|t|)"]
  
  # Function to add significance stars
  get_stars <- function(p) {
    if (p <= 0.01) return("***")
    if (p <= 0.05) return("**")
    if (p <= 0.1) return("*")
    if (p <= 0.15) return(".")
    return("")
  }
  
  # Maximum width for variable names
  name_width <- 60
  
  # Print model name and header
  cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
  cat("MODEL:", model_name, "\n")
  cat(paste(rep("=", 80), collapse=""), "\n\n")
  
  # Print header with alignment
  cat(sprintf("%-*s  %10s  %10s  %4s\n", name_width, "Variable", "t-value", "p-value", "sig"))
  cat(sprintf("%-*s  %10s  %10s  %4s\n", name_width, "---------", "-------", "-------", "----"))
  
  # Loop through and print values
  for (i in 1:length(t_stats)) {
    var_name <- rownames(robust_test)[i]
    # Truncate name if too long
    if (nchar(var_name) > name_width) {
      var_name <- paste0(substr(var_name, 1, name_width-3), "...")
    }
    cat(sprintf("%-*s  %10.4f  %10.4f  %4s\n", 
                name_width, var_name, 
                t_stats[i], p_values[i],
                get_stars(p_values[i])))
  }
  
  cat("\nSignificance codes: 0 '***' 0.01 '**' 0.05 '*' 0.1 '.' 0.15\n")
  
  # Print R-squared
  r_squared <- summary(model)$adj.r.squared
  cat("\nAdjusted R-squared:", r_squared, "\n")
  
  # Calculate VIFs
  library(car)
  vifs <- vif(model)
  
  # Filter to show only VIFs over 5
  high_vifs <- vifs[vifs > 5]
  if(length(high_vifs) > 0) {
    cat("\nVariables with VIF > 5:\n")
    print(high_vifs)
  } else {
    cat("\nNo variables with VIF > 5 found in this model\n")
  }
  
  return(r_squared)
}

# Analyze all models
r2_player <- analyze_model(ols_model_player, "Player Model with GIMR")
r2_starter <- analyze_model(ols_model_starter, "Starter Model with GIMR")
r2_player_no_gimr <- analyze_model(ols_model_player_no_gimr, "Player Model without GIMR")
r2_starter_no_gimr <- analyze_model(ols_model_starter_no_gimr, "Starter Model without GIMR")

# Compare R-squared values
cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
cat("MODEL COMPARISON - Adjusted R-squared values\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")
cat("Player Model with GIMR:", r2_player, "\n")
cat("Starter Model with GIMR:", r2_starter, "\n")
cat("Player Model without GIMR:", r2_player_no_gimr, "\n")
cat("Starter Model without GIMR:", r2_starter_no_gimr, "\n")

# Plot comparison of models
model_names <- c("Player+GIMR", "Starter+GIMR", "Player", "Starter")
r2_values <- c(r2_player, r2_starter, r2_player_no_gimr, r2_starter_no_gimr)
colors <- c("darkblue", "lightblue", "darkred", "lightcoral")

barplot(r2_values, names.arg = model_names, col = colors,
        main = "Model Comparison - Adjusted R-squared",
        ylab = "Adjusted R-squared", ylim = c(0, max(r2_values) * 1.1),
        cex.names = 0.8)

# Add GIMR coefficient comparison for models with GIMR
cat("\n\n", paste(rep("=", 80), collapse=""), "\n")
cat("GIMR COEFFICIENT COMPARISON\n")
cat(paste(rep("=", 80), collapse=""), "\n\n")

gimr_coef_player <- coef(ols_model_player)["GIMR"]
gimr_tstat_player <- coeftest(ols_model_player, vcov = vcovHC(ols_model_player, type = "HC0"))["GIMR", "t value"]
gimr_pval_player <- coeftest(ols_model_player, vcov = vcovHC(ols_model_player, type = "HC0"))["GIMR", "Pr(>|t|)"]

gimr_coef_starter <- coef(ols_model_starter)["GIMR"]
gimr_tstat_starter <- coeftest(ols_model_starter, vcov = vcovHC(ols_model_starter, type = "HC0"))["GIMR", "t value"]
gimr_pval_starter <- coeftest(ols_model_starter, vcov = vcovHC(ols_model_starter, type = "HC0"))["GIMR", "Pr(>|t|)"]

cat("Player Model - GIMR coefficient:", gimr_coef_player, "\n")
cat("Player Model - GIMR t-statistic:", gimr_tstat_player, "\n")
cat("Player Model - GIMR p-value:", gimr_pval_player, "\n\n")

cat("Starter Model - GIMR coefficient:", gimr_coef_starter, "\n")
cat("Starter Model - GIMR t-statistic:", gimr_tstat_starter, "\n")
cat("Starter Model - GIMR p-value:", gimr_pval_starter, "\n")
```

